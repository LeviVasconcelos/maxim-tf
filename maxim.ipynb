{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eoRdYSQqHWt5",
    "outputId": "838d115a-2933-4da4-c446-3e9bf6f4293f"
   },
   "outputs": [],
   "source": [
    "# !pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lIYdn1woOS1n"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 15:30:31.640939: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockImages(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, patch_size):\n",
    "        bs, h, w, num_channels = (\n",
    "            K.int_shape(x)[0],\n",
    "            K.int_shape(x)[1],\n",
    "            K.int_shape(x)[2],\n",
    "            K.int_shape(x)[3],\n",
    "        )\n",
    "\n",
    "        grid_height, grid_width = h // patch_size[0], w // patch_size[1]\n",
    "\n",
    "        x = layers.Reshape(\n",
    "            (grid_height * patch_size[0], grid_width * patch_size[1], num_channels)\n",
    "        )(x)\n",
    "\n",
    "        x = layers.Reshape(\n",
    "            (-1, grid_height * grid_width, patch_size[0] * patch_size[1], num_channels)\n",
    "        )(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnblockImages(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, grid_size, patch_size):\n",
    "        num_channels = K.int_shape(x)[-1]\n",
    "\n",
    "        x = layers.Reshape(\n",
    "            (grid_size[0] * grid_size[1], patch_size[0] * patch_size[1], num_channels)\n",
    "        )(x)\n",
    "\n",
    "        x = layers.Reshape(\n",
    "            (grid_size[0] * patch_size[0], grid_size[1] * patch_size[1], num_channels)\n",
    "        )(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VCVWH1hy1iAm"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "Conv3x3 = functools.partial(layers.Conv2D, kernel_size=(3, 3), padding=\"same\")\n",
    "Conv1x1 = functools.partial(layers.Conv2D, kernel_size=(1, 1), padding=\"same\")\n",
    "ConvT_up = functools.partial(\n",
    "    layers.Conv2DTranspose, kernel_size=(2, 2), strides=(2, 2), padding=\"same\"\n",
    ")\n",
    "Conv_down = functools.partial(\n",
    "    layers.Conv2D, kernel_size=(4, 4), strides=(2, 2), padding=\"same\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GbfPOgQ015Hh"
   },
   "outputs": [],
   "source": [
    "def MlpBlock(\n",
    "    mlp_dim: int,\n",
    "    dropout_rate: float = 0.0,\n",
    "    use_bias: bool = True,\n",
    "    name: str = \"mlp_block\",\n",
    "):\n",
    "    \"\"\"A 1-hidden-layer MLP block, applied over the last dimension.\"\"\"\n",
    "\n",
    "    def apply(x):\n",
    "        d = K.int_shape(x)[-1]\n",
    "        x = layers.Dense(mlp_dim, use_bias=use_bias)(x)\n",
    "        x = tf.nn.gelu(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "        x = layers.Dense(d, use_bias=use_bias)(x)\n",
    "        return x\n",
    "\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MxJYpPqT3pUo"
   },
   "outputs": [],
   "source": [
    "def UpSampleRatio(\n",
    "    num_channels: int, ratio: float, use_bias: bool = True, name: str = \"upsample\"\n",
    "):\n",
    "    \"\"\"Upsample features given a ratio > 0.\"\"\"\n",
    "\n",
    "    def apply(x):\n",
    "        n, h, w, c = (\n",
    "            K.int_shape(x)[0],\n",
    "            K.int_shape(x)[1],\n",
    "            K.int_shape(x)[2],\n",
    "            K.int_shape(x)[3],\n",
    "        )\n",
    "\n",
    "        x = layers.Resizing(\n",
    "            height=tf.cast(h * ratio, tf.int32), width=tf.cast(w * ratio, tf.int32)\n",
    "        )(x)\n",
    "\n",
    "        x = Conv1x1(filters=num_channels, use_bias=use_bias, name=f\"{name}_point_conv\")(x)\n",
    "        return x\n",
    "\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nQ9xDlNv4xze"
   },
   "outputs": [],
   "source": [
    "def CALayer(\n",
    "    num_channels: int,\n",
    "    reduction: int = 4,\n",
    "    use_bias: bool = True,\n",
    "    name: str = \"channel_attention\",\n",
    "):\n",
    "    \"\"\"Squeeze-and-excitation block for channel attention.\n",
    "    ref: https://arxiv.org/abs/1709.01507\n",
    "    \"\"\"\n",
    "\n",
    "    def apply(x):\n",
    "        # 2D global average pooling\n",
    "        y = layers.GlobalAvgPool2D(keepdims=True)(x)\n",
    "        # Squeeze (in Squeeze-Excitation)\n",
    "        y = Conv1x1(filters=num_channels // reduction, use_bias=use_bias)(y)\n",
    "        y = tf.nn.relu(y)\n",
    "        # Excitation (in Squeeze-Excitation)\n",
    "        y = Conv1x1(filters=num_channels, use_bias=use_bias)(y)\n",
    "        y = tf.nn.sigmoid(y)\n",
    "        return x * y\n",
    "\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kqSgeeNd5p2o"
   },
   "outputs": [],
   "source": [
    "def RCAB(\n",
    "    num_channels: int,\n",
    "    reduction: int = 4,\n",
    "    lrelu_slope: float = 0.2,\n",
    "    use_bias: bool = True,\n",
    "    name: str = \"residual_ca\",\n",
    "):\n",
    "    \"\"\"Residual channel attention block. Contains LN,Conv,lRelu,Conv,SELayer.\"\"\"\n",
    "\n",
    "    def apply(x):\n",
    "        shortcut = x\n",
    "        x = layers.LayerNormalization(name=f\"{name}_LayerNorm\")(x)\n",
    "        x = Conv3x3(filters=num_channels, use_bias=use_bias, name=f\"{name}_conv1\")(x)\n",
    "        x = tf.nn.leaky_relu(x, alpha=lrelu_slope)\n",
    "        x = Conv3x3(filters=num_channels, use_bias=use_bias, name=f\"{name}_conv2\")(x)\n",
    "        x = CALayer(\n",
    "            num_channels=num_channels,\n",
    "            reduction=reduction,\n",
    "            use_bias=use_bias,\n",
    "            name=\"channel_attention\",\n",
    "        )(x)\n",
    "        return x + shortcut\n",
    "\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mv4uinTs60aw"
   },
   "outputs": [],
   "source": [
    "def GridGatingUnit(use_bias: bool = True, name: str = \"grid_gating_unit\"):\n",
    "    \"\"\"A SpatialGatingUnit as defined in the gMLP paper.\n",
    "    The 'spatial' dim is defined as the second last.\n",
    "    If applied on other dims, you should swapaxes first.\n",
    "    \"\"\"\n",
    "\n",
    "    def apply(x):\n",
    "        u, v = tf.split(x, 2, axis=-1)\n",
    "        v = layers.LayerNormalization(name=f\"{name}_intermediate_layernorm\")(v)\n",
    "        n = K.int_shape(x)[-3]  # get spatial dim\n",
    "        v = SwapAxes()(v, -1, -3)\n",
    "        v = layers.Dense(n, use_bias=use_bias)(v)\n",
    "        v = SwapAxes()(v, -1, -3)\n",
    "        return u * (v + 1.0)\n",
    "\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridGmlpLayer(\n",
    "    grid_size,\n",
    "    use_bias: bool = True,\n",
    "    factor: int = 2,\n",
    "    dropout_rate: float = 0.0,\n",
    "    name: str = \"grid_gmlp\",\n",
    "):\n",
    "    \"\"\"Grid gMLP layer that performs global mixing of tokens.\"\"\"\n",
    "\n",
    "    def apply(x):\n",
    "        n, h, w, num_channels = (\n",
    "            K.int_shape(x)[0],\n",
    "            K.int_shape(x)[1],\n",
    "            K.int_shape(x)[2],\n",
    "            K.int_shape(x)[3],\n",
    "        )\n",
    "        gh, gw = grid_size\n",
    "        fh, fw = h // gh, w // gw\n",
    "\n",
    "        x = BlockImages()(x, patch_size=(fh, fw))\n",
    "        # gMLP1: Global (grid) mixing part, provides global grid communication.\n",
    "        y = layers.LayerNormalization(name=f\"{name}_LayerNorm\")(x)\n",
    "        y = layers.Dense(\n",
    "            num_channels * factor,\n",
    "            use_bias=use_bias,\n",
    "            name=f\"{name}_in_project\",\n",
    "        )(y)\n",
    "        y = tf.nn.gelu(y)\n",
    "        y = GridGatingUnit(use_bias=use_bias, name=f\"{name}_GridGatingUnit\")(y)\n",
    "        y = layers.Dense(\n",
    "            num_channels,\n",
    "            use_bias=use_bias,\n",
    "            name=f\"{name}_out_project\",\n",
    "        )(y)\n",
    "        y = layers.Dropout(dropout_rate)(y)\n",
    "        x = x + y\n",
    "        x = UnblockImages()(x, grid_size=(gh, gw), patch_size=(fh, fw))\n",
    "        return x\n",
    "\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwapAxes(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, axis_one, axis_two):\n",
    "        return tf.experimental.numpy.swapaxes(x, axis_one, axis_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BlockGatingUnit(use_bias: bool = True, name: str = \"block_gating_unit\"):\n",
    "    \"\"\"A SpatialGatingUnit as defined in the gMLP paper.\n",
    "    The 'spatial' dim is defined as the **second last**.\n",
    "    If applied on other dims, you should swapaxes first.\n",
    "    \"\"\"\n",
    "\n",
    "    def apply(x):\n",
    "        u, v = tf.split(x, 2, axis=-1)\n",
    "        v = layers.LayerNormalization(name=f\"{name}_intermediate_layernorm\")(v)\n",
    "        n = K.int_shape(x)[-2]  # get spatial dim\n",
    "        v = SwapAxes()(v, -1, -2)\n",
    "        v = layers.Dense(n, use_bias=use_bias)(v)\n",
    "        v = SwapAxes()(v, -1, -2)\n",
    "        return u * (v + 1.0)\n",
    "\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BlockGmlpLayer(\n",
    "    block_size,\n",
    "    use_bias: bool = True,\n",
    "    factor: int = 2,\n",
    "    dropout_rate: float = 0.0,\n",
    "    name: str = \"block_gmlp\",\n",
    "):\n",
    "    \"\"\"Block gMLP layer that performs local mixing of tokens.\"\"\"\n",
    "\n",
    "    def apply(x):\n",
    "        n, h, w, num_channels = (\n",
    "            K.int_shape(x)[0],\n",
    "            K.int_shape(x)[1],\n",
    "            K.int_shape(x)[2],\n",
    "            K.int_shape(x)[3],\n",
    "        )\n",
    "        fh, fw = block_size\n",
    "        gh, gw = h // fh, w // fw\n",
    "        x = BlockImages()(x, patch_size=(fh, fw))\n",
    "        # MLP2: Local (block) mixing part, provides within-block communication.\n",
    "        y = layers.LayerNormalization(name=f\"{name}_LayerNorm\")(x)\n",
    "        y = layers.Dense(\n",
    "            num_channels,\n",
    "            use_bias=use_bias,\n",
    "            name=f\"{name}_in_project\",\n",
    "        )(y)\n",
    "        y = tf.nn.gelu(y)\n",
    "        y = BlockGatingUnit(use_bias=use_bias, name=f\"{name}_BlockGatingUnit\")(y)\n",
    "        y = layers.Dense(\n",
    "            num_channels,\n",
    "            use_bias=use_bias,\n",
    "            name=f\"{name}_out_project\",\n",
    "        )(y)\n",
    "        y = layers.Dropout(dropout_rate)(y)\n",
    "        x = x + y\n",
    "        x = UnblockImages()(x, grid_size=(gh, gw), patch_size=(fh, fw))\n",
    "        return x\n",
    "\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResidualSplitHeadMultiAxisGmlpLayer(\n",
    "    block_size,\n",
    "    grid_size,\n",
    "    block_gmlp_factor: int = 2,\n",
    "    grid_gmlp_factor: int = 2,\n",
    "    input_proj_factor: int = 2,\n",
    "    use_bias: bool = True,\n",
    "    dropout_rate: float = 0.0,\n",
    "    name: str = \"residual_split_head_maxim\",\n",
    "):\n",
    "    \"\"\"The multi-axis gated MLP block.\"\"\"\n",
    "\n",
    "    def apply(x):\n",
    "        shortcut = x\n",
    "        n, h, w, num_channels = (\n",
    "            K.int_shape(x)[0],\n",
    "            K.int_shape(x)[1],\n",
    "            K.int_shape(x)[2],\n",
    "            K.int_shape(x)[3],\n",
    "        )\n",
    "        x = layers.LayerNormalization(name=f\"{name}_LayerNorm_in\")(x)\n",
    "\n",
    "        x = layers.Dense(\n",
    "            int(num_channels) * input_proj_factor,\n",
    "            use_bias=use_bias,\n",
    "            name=f\"{name}_in_project\",\n",
    "        )(x)\n",
    "        x = tf.nn.gelu(x)\n",
    "\n",
    "        u, v = tf.split(x, 2, axis=-1)\n",
    "\n",
    "        # GridGMLPLayer\n",
    "        u = GridGmlpLayer(\n",
    "            grid_size=grid_size,\n",
    "            factor=grid_gmlp_factor,\n",
    "            use_bias=use_bias,\n",
    "            dropout_rate=dropout_rate,\n",
    "            name=f\"{name}_GridGmlpLayer\",\n",
    "        )(u)\n",
    "\n",
    "        # BlockGMLPLayer\n",
    "        v = BlockGmlpLayer(\n",
    "            block_size=block_size,\n",
    "            factor=block_gmlp_factor,\n",
    "            use_bias=use_bias,\n",
    "            dropout_rate=dropout_rate,\n",
    "            name=f\"{name}_BlockGmlpLayer\",\n",
    "        )(v)\n",
    "\n",
    "        x = tf.concat([u, v], axis=-1)\n",
    "\n",
    "        x = layers.Dense(\n",
    "            num_channels,\n",
    "            use_bias=use_bias,\n",
    "            name=f\"{name}_out_project\",\n",
    "        )(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "        x = x + shortcut\n",
    "        return x\n",
    "\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RDCAB(\n",
    "    num_channels: int,\n",
    "    reduction: int = 16,\n",
    "    use_bias: bool = True,\n",
    "    dropout_rate: float = 0.0,\n",
    "    name: str = \"rdcab\",\n",
    "):\n",
    "    \"\"\"Residual dense channel attention block. Used in Bottlenecks.\"\"\"\n",
    "\n",
    "    def apply(x):\n",
    "        y = layers.LayerNormalization(name=f\"{name}_LayerNorm\")(x)\n",
    "        y = MlpBlock(\n",
    "            mlp_dim=num_channels,\n",
    "            dropout_rate=dropout_rate,\n",
    "            use_bias=use_bias,\n",
    "            name=\"channel_mixing\",\n",
    "        )(y)\n",
    "        y = CALayer(\n",
    "            num_channels=num_channels,\n",
    "            reduction=reduction,\n",
    "            use_bias=use_bias,\n",
    "            name=\"channel_attention\",\n",
    "        )(y)\n",
    "        x = x + y\n",
    "        return x\n",
    "\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BottleneckBlock(\n",
    "    features: int,\n",
    "    block_size,\n",
    "    grid_size,\n",
    "    num_groups: int = 1,\n",
    "    block_gmlp_factor: int = 2,\n",
    "    grid_gmlp_factor: int = 2,\n",
    "    input_proj_factor: int = 2,\n",
    "    channels_reduction: int = 4,\n",
    "    dropout_rate: float = 0.0,\n",
    "    use_bias: bool = True,\n",
    "    name: str = \"bottleneck_block\",\n",
    "):\n",
    "    \"\"\"The bottleneck block consisting of multi-axis gMLP block and RDCAB.\"\"\"\n",
    "\n",
    "    def apply(x):\n",
    "        \"\"\"Applies the Mixer block to inputs.\"\"\"\n",
    "        n, h, w, num_channels = (\n",
    "            K.int_shape(x)[0],\n",
    "            K.int_shape(x)[1],\n",
    "            K.int_shape(x)[2],\n",
    "            K.int_shape(x)[3],\n",
    "        )\n",
    "        # input projection\n",
    "        x = Conv1x1(filters=features, use_bias=use_bias, name=f\"{name}_input_proj\")(x)\n",
    "        shortcut_long = x\n",
    "\n",
    "        for i in range(num_groups):\n",
    "            x = ResidualSplitHeadMultiAxisGmlpLayer(\n",
    "                grid_size=grid_size,\n",
    "                block_size=block_size,\n",
    "                grid_gmlp_factor=grid_gmlp_factor,\n",
    "                block_gmlp_factor=block_gmlp_factor,\n",
    "                input_proj_factor=input_proj_factor,\n",
    "                use_bias=use_bias,\n",
    "                dropout_rate=dropout_rate,\n",
    "                name=f\"{name}_SplitHeadMultiAxisGmlpLayer_{i}\",\n",
    "            )(x)\n",
    "            # Channel-mixing part, which provides within-patch communication.\n",
    "            x = RDCAB(\n",
    "                num_channels=features,\n",
    "                reduction=channels_reduction,\n",
    "                use_bias=use_bias,\n",
    "                name=f\"{name}_channel_attention_block_1_{i}\",\n",
    "            )(x)\n",
    "\n",
    "        # long skip-connect\n",
    "        x = x + shortcut_long\n",
    "        return x\n",
    "\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNetEncoderBlock(\n",
    "    num_channels: int,\n",
    "    block_size,\n",
    "    grid_size,\n",
    "    num_groups: int = 1,\n",
    "    lrelu_slope: float = 0.2,\n",
    "    block_gmlp_factor: int = 2,\n",
    "    grid_gmlp_factor: int = 2,\n",
    "    input_proj_factor: int = 2,\n",
    "    channels_reduction: int = 4,\n",
    "    dropout_rate: float = 0.0,\n",
    "    downsample: bool = True,\n",
    "    use_global_mlp: bool = True,\n",
    "    use_bias: bool = True,\n",
    "    use_cross_gating: bool = False,\n",
    "    name: str = \"unet_encoder\",\n",
    "):\n",
    "    \"\"\"Encoder block in MAXIM.\"\"\"\n",
    "\n",
    "    def apply(x, skip=None, enc=None, dec=None):\n",
    "        if skip is not None:\n",
    "            x = tf.concat([x, skip], axis=-1)\n",
    "\n",
    "        # convolution-in\n",
    "        x = Conv1x1(filters=num_channels, use_bias=use_bias)(x)\n",
    "        shortcut_long = x\n",
    "\n",
    "        for i in range(num_groups):\n",
    "            if use_global_mlp:\n",
    "                x = ResidualSplitHeadMultiAxisGmlpLayer(\n",
    "                    grid_size=grid_size,\n",
    "                    block_size=block_size,\n",
    "                    grid_gmlp_factor=grid_gmlp_factor,\n",
    "                    block_gmlp_factor=block_gmlp_factor,\n",
    "                    input_proj_factor=input_proj_factor,\n",
    "                    use_bias=use_bias,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                    name=f\"{name}_SplitHeadMultiAxisGmlpLayer_{i}\",\n",
    "                )(x)\n",
    "            x = RCAB(\n",
    "                num_channels=num_channels,\n",
    "                reduction=channels_reduction,\n",
    "                use_bias=use_bias,\n",
    "                name=f\"{name}_channel_attention_block_1{i}\",\n",
    "            )(x)\n",
    "\n",
    "        x = x + shortcut_long\n",
    "\n",
    "        if enc is not None and dec is not None:\n",
    "            x, _ = CrossGatingBlock(\n",
    "                features=num_channels,\n",
    "                block_size=block_size,\n",
    "                grid_size=grid_size,\n",
    "                dropout_rate=dropout_rate,\n",
    "                input_proj_factor=input_proj_factor,\n",
    "                upsample_y=False,\n",
    "                use_bias=use_bias,\n",
    "                name=f\"{name}_cross_gating_block\",\n",
    "            )(x, enc + dec)\n",
    "\n",
    "        if downsample:\n",
    "            x_down = Conv_down(filters=num_channels, use_bias=use_bias)(x)\n",
    "            return x_down, x\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNetDecoderBlock(\n",
    "    num_channels: int,\n",
    "    block_size,\n",
    "    grid_size,\n",
    "    num_groups: int = 1,\n",
    "    lrelu_slope: float = 0.2,\n",
    "    block_gmlp_factor: int = 2,\n",
    "    grid_gmlp_factor: int = 2,\n",
    "    input_proj_factor: int = 2,\n",
    "    channels_reduction: int = 4,\n",
    "    dropout_rate: float = 0.0,\n",
    "    downsample: bool = True,\n",
    "    use_global_mlp: bool = True,\n",
    "    use_bias: bool = True,\n",
    "    name: str = \"unet_decoder\",\n",
    "):\n",
    "\n",
    "    \"\"\"Decoder block in MAXIM.\"\"\"\n",
    "\n",
    "    def apply(x, bridge=None):\n",
    "        x = ConvT_up(filters=num_channels, use_bias=use_bias)(x)\n",
    "        x = UNetEncoderBlock(\n",
    "            num_channels=num_channels,\n",
    "            num_groups=num_groups,\n",
    "            lrelu_slope=lrelu_slope,\n",
    "            block_size=block_size,\n",
    "            grid_size=grid_size,\n",
    "            block_gmlp_factor=block_gmlp_factor,\n",
    "            grid_gmlp_factor=grid_gmlp_factor,\n",
    "            channels_reduction=channels_reduction,\n",
    "            use_global_mlp=use_global_mlp,\n",
    "            dropout_rate=dropout_rate,\n",
    "            downsample=False,\n",
    "            use_bias=use_bias,\n",
    "            name=f\"{name}_unet_encoder\",\n",
    "        )(x, skip=bridge)\n",
    "\n",
    "        return x\n",
    "\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSpatialGatingWeights(\n",
    "    features: int,\n",
    "    block_size,\n",
    "    grid_size,\n",
    "    input_proj_factor: int = 2,\n",
    "    dropout_rate: float = 0.0,\n",
    "    use_bias: bool = True,\n",
    "    name: str = \"spatial_gating\",\n",
    "):\n",
    "\n",
    "    \"\"\"Get gating weights for cross-gating MLP block.\"\"\"\n",
    "\n",
    "    def apply(x):\n",
    "        n, h, w, num_channels = (\n",
    "            K.int_shape(x)[0],\n",
    "            K.int_shape(x)[1],\n",
    "            K.int_shape(x)[2],\n",
    "            K.int_shape(x)[3],\n",
    "        )\n",
    "\n",
    "        # input projection\n",
    "        x = layers.LayerNormalization(name=f\"{name}_LayerNorm_in\")(x)\n",
    "        x = layers.Dense(\n",
    "            num_channels * input_proj_factor,\n",
    "            use_bias=use_bias,\n",
    "            name=f\"{name}_in_project\",\n",
    "        )(x)\n",
    "        x = tf.nn.gelu(x)\n",
    "        u, v = tf.split(x, 2, axis=-1)\n",
    "\n",
    "        # Get grid MLP weights\n",
    "        gh, gw = grid_size\n",
    "        fh, fw = h // gh, w // gw\n",
    "        u = BlockImages()(u, patch_size=(fh, fw))\n",
    "        dim_u = K.int_shape(u)[-3]\n",
    "        u = SwapAxes()(u, -1, -3)\n",
    "        u = layers.Dense(dim_u, use_bias=use_bias)(u)\n",
    "        u = SwapAxes()(u, -1, -3)\n",
    "        u = UnblockImages()(u, grid_size=(gh, gw), patch_size=(fh, fw))\n",
    "\n",
    "        # Get Block MLP weights\n",
    "        fh, fw = block_size\n",
    "        gh, gw = h // fh, w // fw\n",
    "        v = BlockImages()(v, patch_size=(fh, fw))\n",
    "        dim_v = v.shape[-2]\n",
    "        v = SwapAxes()(v, -1, -2)\n",
    "        v = layers.Dense(dim_v, use_bias=use_bias)(v)\n",
    "        v = SwapAxes()(v, -1, -2)\n",
    "        v = UnblockImages()(v, grid_size=(gh, gw), patch_size=(fh, fw))\n",
    "\n",
    "        x = tf.concat([u, v], axis=-1)\n",
    "        x = layers.Dense(num_channels, use_bias=use_bias, name=f\"{name}_out_project\")(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "        return x\n",
    "\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossGatingBlock(\n",
    "    features: int,\n",
    "    block_size,\n",
    "    grid_size,\n",
    "    dropout_rate: float = 0.0,\n",
    "    input_proj_factor: int = 2,\n",
    "    upsample_y: bool = True,\n",
    "    use_bias: bool = True,\n",
    "    name: str = \"cross_gating\",\n",
    "):\n",
    "\n",
    "    \"\"\"Cross-gating MLP block.\"\"\"\n",
    "\n",
    "    def apply(x, y):\n",
    "        # Upscale Y signal, y is the gating signal.\n",
    "        if upsample_y:\n",
    "            y = ConvT_up(filters=features, use_bias=use_bias)(y)\n",
    "\n",
    "        x = Conv1x1(filters=features, use_bias=use_bias)(x)\n",
    "        n, h, w, num_channels = (\n",
    "            K.int_shape(x)[0],\n",
    "            K.int_shape(x)[1],\n",
    "            K.int_shape(x)[2],\n",
    "            K.int_shape(x)[3],\n",
    "        )\n",
    "\n",
    "        y = Conv1x1(filters=num_channels, use_bias=use_bias)(y)\n",
    "\n",
    "        shortcut_x = x\n",
    "        shortcut_y = y\n",
    "\n",
    "        # Get gating weights from X\n",
    "        x = layers.LayerNormalization(name=f\"{name}_LayerNorm_x\")(x)\n",
    "        x = layers.Dense(num_channels, use_bias=use_bias, name=f\"{name}_in_project_x\")(\n",
    "            x\n",
    "        )\n",
    "        x = tf.nn.gelu(x)\n",
    "        gx = GetSpatialGatingWeights(\n",
    "            features=num_channels,\n",
    "            block_size=block_size,\n",
    "            grid_size=grid_size,\n",
    "            dropout_rate=dropout_rate,\n",
    "            use_bias=use_bias,\n",
    "            name=f\"{name}_SplitHeadMultiAxisGating_x\",\n",
    "        )(x)\n",
    "\n",
    "        # Get gating weights from Y\n",
    "        y = layers.LayerNormalization(name=f\"{name}_LayerNorm_y\")(y)\n",
    "        y = layers.Dense(num_channels, use_bias=use_bias, name=f\"{name}_in_project_y\")(\n",
    "            y\n",
    "        )\n",
    "        y = tf.nn.gelu(y)\n",
    "        gy = GetSpatialGatingWeights(\n",
    "            features=num_channels,\n",
    "            block_size=block_size,\n",
    "            grid_size=grid_size,\n",
    "            dropout_rate=dropout_rate,\n",
    "            use_bias=use_bias,\n",
    "            name=f\"{name}_SplitHeadMultiAxisGating_y\",\n",
    "        )(y)\n",
    "\n",
    "        # Apply cross gating: X = X * GY, Y = Y * GX\n",
    "        y = y * gx\n",
    "        y = layers.Dense(num_channels, use_bias=use_bias, name=f\"{name}_out_project_y\")(\n",
    "            y\n",
    "        )\n",
    "        y = layers.Dropout(dropout_rate)(y)\n",
    "        y = y + shortcut_y\n",
    "\n",
    "        x = x * gy  # gating x using y\n",
    "        x = layers.Dense(num_channels, use_bias=use_bias, name=f\"{name}_out_project_x\")(\n",
    "            x\n",
    "        )\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "        x = x + y + shortcut_x  # get all aggregated signals\n",
    "        return x, y\n",
    "\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SAM(\n",
    "    num_channels: int,\n",
    "    output_channels: int = 3,\n",
    "    use_bias: bool = True,\n",
    "    name: str = \"sam\",\n",
    "):\n",
    "\n",
    "    \"\"\"Supervised attention module for multi-stage training.\n",
    "    Introduced by MPRNet [CVPR2021]: https://github.com/swz30/MPRNet\n",
    "    \"\"\"\n",
    "\n",
    "    def apply(x, x_image):\n",
    "        \"\"\"Apply the SAM module to the input and num_channels.\n",
    "        Args:\n",
    "          x: the output num_channels from UNet decoder with shape (h, w, c)\n",
    "          x_image: the input image with shape (h, w, 3)\n",
    "        Returns:\n",
    "          A tuple of tensors (x1, image) where (x1) is the sam num_channels used for the\n",
    "            next stage, and (image) is the output restored image at current stage.\n",
    "        \"\"\"\n",
    "        # Get num_channels\n",
    "        x1 = Conv3x3(filters=num_channels, use_bias=use_bias)(x)\n",
    "\n",
    "        # Output restored image X_s\n",
    "        if output_channels == 3:\n",
    "            image = Conv3x3(filters=output_channels, use_bias=use_bias)(x) + x_image\n",
    "        else:\n",
    "            image = Conv3x3(filters=output_channels, use_bias=use_bias)(x)\n",
    "\n",
    "        # Get attention maps for num_channels\n",
    "        x2 = tf.nn.sigmoid(Conv3x3(filters=num_channels, use_bias=use_bias)(image))\n",
    "\n",
    "        # Get attended feature maps\n",
    "        x1 = x1 * x2\n",
    "\n",
    "        # Residual connection\n",
    "        x1 = x1 + x\n",
    "        return x1, image\n",
    "\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAXIM(\n",
    "    features: int = 64,\n",
    "    depth: int = 3,\n",
    "    num_stages: int = 2,\n",
    "    num_groups: int = 1,\n",
    "    use_bias: bool = True,\n",
    "    num_supervision_scales: int = 1,\n",
    "    lrelu_slope: float = 0.2,\n",
    "    use_global_mlp: bool = True,\n",
    "    use_cross_gating: bool = True,\n",
    "    high_res_stages: int = 2,\n",
    "    block_size_hr=(16, 16),\n",
    "    block_size_lr=(8, 8),\n",
    "    grid_size_hr=(16, 16),\n",
    "    grid_size_lr=(8, 8),\n",
    "    num_bottleneck_blocks: int = 1,\n",
    "    block_gmlp_factor: int = 2,\n",
    "    grid_gmlp_factor: int = 2,\n",
    "    input_proj_factor: int = 2,\n",
    "    channels_reduction: int = 4,\n",
    "    num_outputs: int = 3,\n",
    "    dropout_rate: float = 0.0,\n",
    "):\n",
    "    \"\"\"The MAXIM model function with multi-stage and multi-scale supervision.\n",
    "    For more model details, please check the CVPR paper:\n",
    "    MAXIM: MUlti-Axis MLP for Image Processing (https://arxiv.org/abs/2201.02973)\n",
    "    Attributes:\n",
    "      features: initial hidden dimension for the input resolution.\n",
    "      depth: the number of downsampling depth for the model.\n",
    "      num_stages: how many stages to use. It will also affects the output list.\n",
    "      num_groups: how many blocks each stage contains.\n",
    "      use_bias: whether to use bias in all the conv/mlp layers.\n",
    "      num_supervision_scales: the number of desired supervision scales.\n",
    "      lrelu_slope: the negative slope parameter in leaky_relu layers.\n",
    "      use_global_mlp: whether to use the multi-axis gated MLP block (MAB) in each\n",
    "        layer.\n",
    "      use_cross_gating: whether to use the cross-gating MLP block (CGB) in the\n",
    "        skip connections and multi-stage feature fusion layers.\n",
    "      high_res_stages: how many stages are specificied as high-res stages. The\n",
    "        rest (depth - high_res_stages) are called low_res_stages.\n",
    "      block_size_hr: the block_size parameter for high-res stages.\n",
    "      block_size_lr: the block_size parameter for low-res stages.\n",
    "      grid_size_hr: the grid_size parameter for high-res stages.\n",
    "      grid_size_lr: the grid_size parameter for low-res stages.\n",
    "      num_bottleneck_blocks: how many bottleneck blocks.\n",
    "      block_gmlp_factor: the input projection factor for block_gMLP layers.\n",
    "      grid_gmlp_factor: the input projection factor for grid_gMLP layers.\n",
    "      input_proj_factor: the input projection factor for the MAB block.\n",
    "      channels_reduction: the channel reduction factor for SE layer.\n",
    "      num_outputs: the output channels.\n",
    "      dropout_rate: Dropout rate.\n",
    "    Returns:\n",
    "      The output contains a list of arrays consisting of multi-stage multi-scale\n",
    "      outputs. For example, if num_stages = num_supervision_scales = 3 (the\n",
    "      model used in the paper), the output specs are: outputs =\n",
    "      [[output_stage1_scale1, output_stage1_scale2, output_stage1_scale3],\n",
    "       [output_stage2_scale1, output_stage2_scale2, output_stage2_scale3],\n",
    "       [output_stage3_scale1, output_stage3_scale2, output_stage3_scale3],]\n",
    "      The final output can be retrieved by outputs[-1][-1].\n",
    "    \"\"\"\n",
    "\n",
    "    def apply(x):\n",
    "        n, h, w, c = (\n",
    "            K.int_shape(x)[0],\n",
    "            K.int_shape(x)[1],\n",
    "            K.int_shape(x)[2],\n",
    "            K.int_shape(x)[3],\n",
    "        )  # input image shape\n",
    "\n",
    "        shortcuts = []\n",
    "        shortcuts.append(x)\n",
    "\n",
    "        # Get multi-scale input images\n",
    "        for i in range(1, num_supervision_scales):\n",
    "            resizing_layer = layers.Resizing(\n",
    "                height=h // (2**i), width=w // (2**i), method=\"nearest\"\n",
    "            )\n",
    "            shortcuts.append(resizing_layer(x))\n",
    "\n",
    "        # store outputs from all stages and all scales\n",
    "        # Eg, [[(64, 64, 3), (128, 128, 3), (256, 256, 3)],   # Stage-1 outputs\n",
    "        #      [(64, 64, 3), (128, 128, 3), (256, 256, 3)],]  # Stage-2 outputs\n",
    "        outputs_all = []\n",
    "        sam_features, encs_prev, decs_prev = [], [], []\n",
    "\n",
    "        for idx_stage in range(num_stages):\n",
    "            # Input convolution, get multi-scale input features\n",
    "            x_scales = []\n",
    "            for i in range(num_supervision_scales):\n",
    "                x_scale = Conv3x3(\n",
    "                    filters=(2**i) * features,\n",
    "                    use_bias=use_bias,\n",
    "                    name=f\"stage_{idx_stage}_input_conv_{i}\",\n",
    "                )(shortcuts[i])\n",
    "\n",
    "                # If later stages, fuse input features with SAM features from prev stage\n",
    "                if idx_stage > 0:\n",
    "                    # use larger blocksize at high-res stages\n",
    "                    if use_cross_gating:\n",
    "                        block_size = (\n",
    "                            block_size_hr if i < high_res_stages else block_size_lr\n",
    "                        )\n",
    "                        grid_size = (\n",
    "                            grid_size_hr if i < high_res_stages else block_size_lr\n",
    "                        )\n",
    "                        x_scale, _ = CrossGatingBlock(\n",
    "                            features=(2**i) * features,\n",
    "                            block_size=block_size,\n",
    "                            grid_size=grid_size,\n",
    "                            dropout_rate=dropout_rate,\n",
    "                            input_proj_factor=input_proj_factor,\n",
    "                            upsample_y=False,\n",
    "                            use_bias=use_bias,\n",
    "                            name=f\"stage_{idx_stage}_input_fuse_sam_{i}\",\n",
    "                        )(x_scale, sam_features.pop())\n",
    "                    else:\n",
    "                        x_scale = Conv1x1(\n",
    "                            filters=(2**i) * features,\n",
    "                            use_bias=use_bias,\n",
    "                            name=f\"stage_{idx_stage}_input_catconv_{i}\",\n",
    "                        )(tf.concat([x_scale, sam_features.pop()], axis=-1))\n",
    "\n",
    "                x_scales.append(x_scale)\n",
    "\n",
    "            # start encoder blocks\n",
    "            encs = []\n",
    "            x = x_scales[0]  # First full-scale input feature\n",
    "\n",
    "            for i in range(depth):  # 0, 1, 2\n",
    "                # use larger blocksize at high-res stages, vice versa.\n",
    "                block_size = block_size_hr if i < high_res_stages else block_size_lr\n",
    "                grid_size = grid_size_hr if i < high_res_stages else block_size_lr\n",
    "                use_cross_gating_layer = True if idx_stage > 0 else False\n",
    "\n",
    "                # Multi-scale input if multi-scale supervision\n",
    "                x_scale = x_scales[i] if i < num_supervision_scales else None\n",
    "\n",
    "                # UNet Encoder block\n",
    "                enc_prev = encs_prev.pop() if idx_stage > 0 else None\n",
    "                dec_prev = decs_prev.pop() if idx_stage > 0 else None\n",
    "\n",
    "                x, bridge = UNetEncoderBlock(\n",
    "                    num_channels=(2**i) * features,\n",
    "                    num_groups=num_groups,\n",
    "                    downsample=True,\n",
    "                    lrelu_slope=lrelu_slope,\n",
    "                    block_size=block_size,\n",
    "                    grid_size=grid_size,\n",
    "                    block_gmlp_factor=block_gmlp_factor,\n",
    "                    grid_gmlp_factor=grid_gmlp_factor,\n",
    "                    input_proj_factor=input_proj_factor,\n",
    "                    channels_reduction=channels_reduction,\n",
    "                    use_global_mlp=use_global_mlp,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                    use_bias=use_bias,\n",
    "                    use_cross_gating=use_cross_gating_layer,\n",
    "                    name=f\"stage_{idx_stage}_encoder_block_{i}\",\n",
    "                )(x, skip=x_scale, enc=enc_prev, dec=dec_prev)\n",
    "\n",
    "                # Cache skip signals\n",
    "                encs.append(bridge)\n",
    "\n",
    "            # Global MLP bottleneck blocks\n",
    "            for i in range(num_bottleneck_blocks):\n",
    "                x = BottleneckBlock(\n",
    "                    block_size=block_size_lr,\n",
    "                    grid_size=block_size_lr,\n",
    "                    features=(2 ** (depth - 1)) * features,\n",
    "                    num_groups=num_groups,\n",
    "                    block_gmlp_factor=block_gmlp_factor,\n",
    "                    grid_gmlp_factor=grid_gmlp_factor,\n",
    "                    input_proj_factor=input_proj_factor,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                    use_bias=use_bias,\n",
    "                    channels_reduction=channels_reduction,\n",
    "                    name=f\"stage_{idx_stage}_global_block_{i}\",\n",
    "                )(x)\n",
    "            # cache global feature for cross-gating\n",
    "            global_feature = x\n",
    "\n",
    "            # start cross gating. Use multi-scale feature fusion\n",
    "            skip_features = []\n",
    "            for i in reversed(range(depth)):  # 2, 1, 0\n",
    "                # use larger blocksize at high-res stages\n",
    "                block_size = block_size_hr if i < high_res_stages else block_size_lr\n",
    "                grid_size = grid_size_hr if i < high_res_stages else block_size_lr\n",
    "\n",
    "                # get additional multi-scale signals\n",
    "                signal = tf.concat(\n",
    "                    [\n",
    "                        UpSampleRatio(\n",
    "                            num_channels=(2**i) * features,\n",
    "                            ratio=2 ** (j - i),\n",
    "                            use_bias=use_bias,\n",
    "                            name=f\"stage_{idx_stage}_upsample_ratio_{i}_{j}_encoder\"\n",
    "                        )(enc)\n",
    "                        for j, enc in enumerate(encs)\n",
    "                    ],\n",
    "                    axis=-1,\n",
    "                )\n",
    "\n",
    "                # Use cross-gating to cross modulate features\n",
    "                if use_cross_gating:\n",
    "                    skips, global_feature = CrossGatingBlock(\n",
    "                        features=(2**i) * features,\n",
    "                        block_size=block_size,\n",
    "                        grid_size=grid_size,\n",
    "                        input_proj_factor=input_proj_factor,\n",
    "                        dropout_rate=dropout_rate,\n",
    "                        upsample_y=True,\n",
    "                        use_bias=use_bias,\n",
    "                        name=f\"stage_{idx_stage}_cross_gating_block_{i}\",\n",
    "                    )(signal, global_feature)\n",
    "                else:\n",
    "                    skips = Conv1x1(filters=(2**i) * features, use_bias=use_bias)(\n",
    "                        signal\n",
    "                    )\n",
    "                    skips = Conv3x3(filters=(2**i) * features, use_bias=use_bias)(\n",
    "                        skips\n",
    "                    )\n",
    "\n",
    "                skip_features.append(skips)\n",
    "\n",
    "            # start decoder. Multi-scale feature fusion of cross-gated features\n",
    "            outputs, decs, sam_features = [], [], []\n",
    "            for i in reversed(range(depth)):\n",
    "                # use larger blocksize at high-res stages\n",
    "                block_size = block_size_hr if i < high_res_stages else block_size_lr\n",
    "                grid_size = grid_size_hr if i < high_res_stages else block_size_lr\n",
    "\n",
    "                # get multi-scale skip signals from cross-gating block\n",
    "                signal = tf.concat(\n",
    "                    [\n",
    "                        UpSampleRatio(\n",
    "                            num_channels=(2**i) * features,\n",
    "                            ratio=2 ** (depth - j - 1 - i),\n",
    "                            use_bias=use_bias,\n",
    "                            name=f\"stage_{idx_stage}_upsample_ratio_{i}_{j}_decoder\",\n",
    "                        )(skip)\n",
    "                        for j, skip in enumerate(skip_features)\n",
    "                    ],\n",
    "                    axis=-1,\n",
    "                )\n",
    "\n",
    "                # Decoder block\n",
    "                x = UNetDecoderBlock(\n",
    "                    num_channels=(2**i) * features,\n",
    "                    num_groups=num_groups,\n",
    "                    lrelu_slope=lrelu_slope,\n",
    "                    block_size=block_size,\n",
    "                    grid_size=grid_size,\n",
    "                    block_gmlp_factor=block_gmlp_factor,\n",
    "                    grid_gmlp_factor=grid_gmlp_factor,\n",
    "                    input_proj_factor=input_proj_factor,\n",
    "                    channels_reduction=channels_reduction,\n",
    "                    use_global_mlp=use_global_mlp,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                    use_bias=use_bias,\n",
    "                    name=f\"stage_{idx_stage}_decoder_block_{i}\",\n",
    "                )(x, bridge=signal)\n",
    "\n",
    "                # Cache decoder features for later-stage's usage\n",
    "                decs.append(x)\n",
    "\n",
    "                # output conv, if not final stage, use supervised-attention-block.\n",
    "                if i < num_supervision_scales:\n",
    "                    if idx_stage < num_stages - 1:  # not last stage, apply SAM\n",
    "                        sam, output = SAM(\n",
    "                            num_channels=(2**i) * features,\n",
    "                            output_channels=num_outputs,\n",
    "                            use_bias=use_bias,\n",
    "                            name=f\"stage_{idx_stage}_supervised_attention_module_{i}\",\n",
    "                        )(x, shortcuts[i])\n",
    "                        outputs.append(output)\n",
    "                        sam_features.append(sam)\n",
    "                    else:  # Last stage, apply output convolutions\n",
    "                        output = Conv3x3(\n",
    "                            num_outputs,\n",
    "                            use_bias=use_bias,\n",
    "                            name=f\"stage_{idx_stage}_output_conv_{i}\",\n",
    "                        )(x)\n",
    "                        output = output + shortcuts[i]\n",
    "                        outputs.append(output)\n",
    "            # Cache encoder and decoder features for later-stage's usage\n",
    "            encs_prev = encs[::-1]\n",
    "            decs_prev = decs\n",
    "\n",
    "            # Store outputs\n",
    "            outputs_all.append(outputs)\n",
    "        return outputs_all\n",
    "\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(variant=None, training=False, **kw):\n",
    "    \"\"\"Factory function to easily create a Model variant like \"S\".\n",
    "    Every model file should have this Model() function that returns the flax\n",
    "    model function. The function name should be fixed.\n",
    "    Args:\n",
    "      variant: UNet model variants. Options: 'S-1' | 'S-2' | 'S-3'\n",
    "          | 'M-1' | 'M-2' | 'M-3'\n",
    "      training: Set it to False during inference. Optionally, modify this\n",
    "          method to have finer controls over how layers within MAXIM should\n",
    "          unfrozen.\n",
    "      **kw: Other UNet config dicts.\n",
    "    Returns:\n",
    "      The MAXIM() model function\n",
    "    \"\"\"\n",
    "\n",
    "    if variant is not None:\n",
    "        config = {\n",
    "            # params: 6.108515000000001 M, GFLOPS: 93.163716608\n",
    "            \"S-1\": {\n",
    "                \"features\": 32,\n",
    "                \"depth\": 3,\n",
    "                \"num_stages\": 1,\n",
    "                \"num_groups\": 2,\n",
    "                \"num_bottleneck_blocks\": 2,\n",
    "                \"block_gmlp_factor\": 2,\n",
    "                \"grid_gmlp_factor\": 2,\n",
    "                \"input_proj_factor\": 2,\n",
    "                \"channels_reduction\": 4,\n",
    "                \"name\": \"s1\",\n",
    "            },\n",
    "            # params: 13.35383 M, GFLOPS: 206.743273472\n",
    "            \"S-2\": {\n",
    "                \"features\": 32,\n",
    "                \"depth\": 3,\n",
    "                \"num_stages\": 2,\n",
    "                \"num_groups\": 2,\n",
    "                \"num_bottleneck_blocks\": 2,\n",
    "                \"block_gmlp_factor\": 2,\n",
    "                \"grid_gmlp_factor\": 2,\n",
    "                \"input_proj_factor\": 2,\n",
    "                \"channels_reduction\": 4,\n",
    "                \"name\": \"s2\",\n",
    "            },\n",
    "            # params: 20.599145 M, GFLOPS: 320.32194560000005\n",
    "            \"S-3\": {\n",
    "                \"features\": 32,\n",
    "                \"depth\": 3,\n",
    "                \"num_stages\": 3,\n",
    "                \"num_groups\": 2,\n",
    "                \"num_bottleneck_blocks\": 2,\n",
    "                \"block_gmlp_factor\": 2,\n",
    "                \"grid_gmlp_factor\": 2,\n",
    "                \"input_proj_factor\": 2,\n",
    "                \"channels_reduction\": 4,\n",
    "                \"name\": \"s3\",\n",
    "            },\n",
    "            # params: 19.361219000000002 M, 308.495712256 GFLOPs\n",
    "            \"M-1\": {\n",
    "                \"features\": 64,\n",
    "                \"depth\": 3,\n",
    "                \"num_stages\": 1,\n",
    "                \"num_groups\": 2,\n",
    "                \"num_bottleneck_blocks\": 2,\n",
    "                \"block_gmlp_factor\": 2,\n",
    "                \"grid_gmlp_factor\": 2,\n",
    "                \"input_proj_factor\": 2,\n",
    "                \"channels_reduction\": 4,\n",
    "                \"name\": \"m1\",\n",
    "            },\n",
    "            # params: 40.83911 M, 675.25541888 GFLOPs\n",
    "            \"M-2\": {\n",
    "                \"features\": 64,\n",
    "                \"depth\": 3,\n",
    "                \"num_stages\": 2,\n",
    "                \"num_groups\": 2,\n",
    "                \"num_bottleneck_blocks\": 2,\n",
    "                \"block_gmlp_factor\": 2,\n",
    "                \"grid_gmlp_factor\": 2,\n",
    "                \"input_proj_factor\": 2,\n",
    "                \"channels_reduction\": 4,\n",
    "                \"name\": \"m2\",\n",
    "            },\n",
    "            # params: 62.317001 M, 1042.014666752 GFLOPs\n",
    "            \"M-3\": {\n",
    "                \"features\": 64,\n",
    "                \"depth\": 3,\n",
    "                \"num_stages\": 3,\n",
    "                \"num_groups\": 2,\n",
    "                \"num_bottleneck_blocks\": 2,\n",
    "                \"block_gmlp_factor\": 2,\n",
    "                \"grid_gmlp_factor\": 2,\n",
    "                \"input_proj_factor\": 2,\n",
    "                \"channels_reduction\": 4,\n",
    "                \"name\": \"m3\",\n",
    "            },\n",
    "        }[variant]\n",
    "\n",
    "        for k, v in config.items():\n",
    "            if k != \"name\":\n",
    "                kw.setdefault(k, v)\n",
    "\n",
    "    inputs = keras.Input((256, 256, 3))\n",
    "    maxim_model = MAXIM(**kw)\n",
    "    outputs = maxim_model(inputs)\n",
    "    final_model = keras.Model(inputs, outputs, name=f'{config[\"name\"]}_model')\n",
    "\n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mod_padding_symmetric(image, factor=64):\n",
    "#   \"\"\"Padding the image to be divided by factor.\"\"\"\n",
    "#   height, width = image.shape[0], image.shape[1]\n",
    "#   height_pad, width_pad = ((height + factor) // factor) * factor, (\n",
    "#       (width + factor) // factor) * factor\n",
    "#   padh = height_pad - height if height % factor != 0 else 0\n",
    "#   padw = width_pad - width if width % factor != 0 else 0\n",
    "#   image = np.pad(\n",
    "#       image, [(padh // 2, padh // 2), (padw // 2, padw // 2), (0, 0)],\n",
    "#       mode='reflect')\n",
    "#   return image\n",
    "\n",
    "\n",
    "# image = np.random.randn(512, 512, 3)\n",
    "# mod_padding_symmetric(image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 15:30:36.165185: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "maxim_s1 = Model(variant=\"S-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy_inputs = tf.ones((1, 256, 256, 3))\n",
    "\n",
    "# # Warmup\n",
    "# print(\"Benchmarking TF model...\")\n",
    "# for _ in range(2):\n",
    "#     _ = maxim_s1(dummy_inputs, training=False)\n",
    "\n",
    "# # Timing\n",
    "# tf_runtimes = timeit.repeat(\n",
    "#     lambda: maxim_s1(dummy_inputs, training=False), number=1, repeat=10\n",
    "# )\n",
    "# print(f\"Average latency (seconds): {np.mean(tf_runtimes)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function(jit_compile=True)\n",
    "# def infer(x):\n",
    "#     return maxim_s1(x, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Warmup\n",
    "# print(\"Benchmarking Jit-compiled TF model...\")\n",
    "# for _ in range(2):\n",
    "#     _ = infer(dummy_inputs)\n",
    "\n",
    "# # Timing\n",
    "# tf_runtimes = timeit.repeat(lambda: infer(dummy_inputs), number=1, repeat=10)\n",
    "# print(f\"Average latency (seconds): {np.mean(tf_runtimes)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import io\n",
    "\n",
    "\n",
    "ckpt_path = \"gs://gresearch/maxim/ckpt/Denoising/SIDD/checkpoint.npz\"\n",
    "\n",
    "\n",
    "def recover_tree(keys, values):\n",
    "    \"\"\"Recovers a tree as a nested dict from flat names and values.\n",
    "    This function is useful to analyze checkpoints that are saved by our programs\n",
    "    without need to access the exact source code of the experiment. In particular,\n",
    "    it can be used to extract an reuse various subtrees of the scheckpoint, e.g.\n",
    "    subtree of parameters.\n",
    "    Args:\n",
    "      keys: a list of keys, where '/' is used as separator between nodes.\n",
    "      values: a list of leaf values.\n",
    "    Returns:\n",
    "      A nested tree-like dict.\n",
    "    \"\"\"\n",
    "    tree = {}\n",
    "    sub_trees = collections.defaultdict(list)\n",
    "    for k, v in zip(keys, values):\n",
    "        if \"/\" not in k:\n",
    "            tree[k] = v\n",
    "        else:\n",
    "            k_left, k_right = k.split(\"/\", 1)\n",
    "            sub_trees[k_left].append((k_right, v))\n",
    "    for k, kv_pairs in sub_trees.items():\n",
    "        k_subtree, v_subtree = zip(*kv_pairs)\n",
    "        tree[k] = recover_tree(k_subtree, v_subtree)\n",
    "    return tree\n",
    "\n",
    "\n",
    "def get_params(ckpt_path):\n",
    "    \"\"\"Get params checkpoint.\"\"\"\n",
    "\n",
    "    with tf.io.gfile.GFile(ckpt_path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    values = np.load(io.BytesIO(data))\n",
    "    params = recover_tree(*zip(*values.items()))\n",
    "    params = params[\"opt\"][\"target\"]\n",
    "\n",
    "    return params\n",
    "\n",
    "\n",
    "params = get_params(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['UpSampleRatio_0', 'UpSampleRatio_1', 'UpSampleRatio_10', 'UpSampleRatio_11', 'UpSampleRatio_12', 'UpSampleRatio_13', 'UpSampleRatio_14', 'UpSampleRatio_15', 'UpSampleRatio_16', 'UpSampleRatio_17', 'UpSampleRatio_18', 'UpSampleRatio_19', 'UpSampleRatio_2', 'UpSampleRatio_20', 'UpSampleRatio_21', 'UpSampleRatio_22', 'UpSampleRatio_23', 'UpSampleRatio_24', 'UpSampleRatio_25', 'UpSampleRatio_26', 'UpSampleRatio_27', 'UpSampleRatio_28', 'UpSampleRatio_29', 'UpSampleRatio_3', 'UpSampleRatio_30', 'UpSampleRatio_31', 'UpSampleRatio_32', 'UpSampleRatio_33', 'UpSampleRatio_34', 'UpSampleRatio_35', 'UpSampleRatio_36', 'UpSampleRatio_37', 'UpSampleRatio_38', 'UpSampleRatio_39', 'UpSampleRatio_4', 'UpSampleRatio_40', 'UpSampleRatio_41', 'UpSampleRatio_42', 'UpSampleRatio_43', 'UpSampleRatio_44', 'UpSampleRatio_45', 'UpSampleRatio_46', 'UpSampleRatio_47', 'UpSampleRatio_48', 'UpSampleRatio_49', 'UpSampleRatio_5', 'UpSampleRatio_50', 'UpSampleRatio_51', 'UpSampleRatio_52', 'UpSampleRatio_53', 'UpSampleRatio_6', 'UpSampleRatio_7', 'UpSampleRatio_8', 'UpSampleRatio_9', 'stage_0_cross_gating_block_0', 'stage_0_cross_gating_block_1', 'stage_0_cross_gating_block_2', 'stage_0_decoder_block_0', 'stage_0_decoder_block_1', 'stage_0_decoder_block_2', 'stage_0_encoder_block_0', 'stage_0_encoder_block_1', 'stage_0_encoder_block_2', 'stage_0_global_block_0', 'stage_0_global_block_1', 'stage_0_input_conv_0', 'stage_0_input_conv_1', 'stage_0_input_conv_2', 'stage_0_supervised_attention_module_0', 'stage_0_supervised_attention_module_1', 'stage_0_supervised_attention_module_2', 'stage_1_cross_gating_block_0', 'stage_1_cross_gating_block_1', 'stage_1_cross_gating_block_2', 'stage_1_decoder_block_0', 'stage_1_decoder_block_1', 'stage_1_decoder_block_2', 'stage_1_encoder_block_0', 'stage_1_encoder_block_1', 'stage_1_encoder_block_2', 'stage_1_global_block_0', 'stage_1_global_block_1', 'stage_1_input_conv_0', 'stage_1_input_conv_1', 'stage_1_input_conv_2', 'stage_1_input_fuse_sam_0', 'stage_1_input_fuse_sam_1', 'stage_1_input_fuse_sam_2', 'stage_1_supervised_attention_module_0', 'stage_1_supervised_attention_module_1', 'stage_1_supervised_attention_module_2', 'stage_2_cross_gating_block_0', 'stage_2_cross_gating_block_1', 'stage_2_cross_gating_block_2', 'stage_2_decoder_block_0', 'stage_2_decoder_block_1', 'stage_2_decoder_block_2', 'stage_2_encoder_block_0', 'stage_2_encoder_block_1', 'stage_2_encoder_block_2', 'stage_2_global_block_0', 'stage_2_global_block_1', 'stage_2_input_conv_0', 'stage_2_input_conv_1', 'stage_2_input_conv_2', 'stage_2_input_fuse_sam_0', 'stage_2_input_fuse_sam_1', 'stage_2_input_fuse_sam_2', 'stage_2_output_conv_0', 'stage_2_output_conv_1', 'stage_2_output_conv_2'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 32, 128)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[\"UpSampleRatio_0\"][\"Conv_0\"][\"kernel\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_vars(model):\n",
    "    model_variables = model.variables\n",
    "    model_variables_dict = {}\n",
    "    for v in model_variables:\n",
    "        model_variables_dict[v.name] = v\n",
    "\n",
    "    return model_variables_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['stage_0_input_conv_0/kernel:0', 'stage_0_input_conv_0/bias:0', 'conv2d/kernel:0', 'conv2d/bias:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/gamma:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/beta:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_in_project/kernel:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_in_project/bias:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/gamma:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/beta:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/beta:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/kernel:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/bias:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/kernel:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/bias:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/kernel:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/bias:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/kernel:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/bias:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_out_project/kernel:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_out_project/bias:0', 'stage_0_encoder_block_0_channel_attention_block_10_LayerNorm/gamma:0', 'stage_0_encoder_block_0_channel_attention_block_10_LayerNorm/beta:0', 'stage_0_encoder_block_0_channel_attention_block_10_conv1/kernel:0', 'stage_0_encoder_block_0_channel_attention_block_10_conv1/bias:0', 'stage_0_encoder_block_0_channel_attention_block_10_conv2/kernel:0', 'stage_0_encoder_block_0_channel_attention_block_10_conv2/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/gamma:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/beta:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_in_project/kernel:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_in_project/bias:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/gamma:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/beta:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/beta:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/kernel:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/bias:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/kernel:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/bias:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/kernel:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/bias:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/kernel:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/bias:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_out_project/kernel:0', 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_out_project/bias:0', 'stage_0_encoder_block_0_channel_attention_block_11_LayerNorm/gamma:0', 'stage_0_encoder_block_0_channel_attention_block_11_LayerNorm/beta:0', 'stage_0_encoder_block_0_channel_attention_block_11_conv1/kernel:0', 'stage_0_encoder_block_0_channel_attention_block_11_conv1/bias:0', 'stage_0_encoder_block_0_channel_attention_block_11_conv2/kernel:0', 'stage_0_encoder_block_0_channel_attention_block_11_conv2/bias:0', 'conv2d_3/kernel:0', 'conv2d_3/bias:0', 'conv2d_4/kernel:0', 'conv2d_4/bias:0', 'conv2d_5/kernel:0', 'conv2d_5/bias:0', 'conv2d_6/kernel:0', 'conv2d_6/bias:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/gamma:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/beta:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_in_project/kernel:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_in_project/bias:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/gamma:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/beta:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/beta:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/kernel:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/bias:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/kernel:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/bias:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_4/kernel:0', 'dense_4/bias:0', 'dense_5/kernel:0', 'dense_5/bias:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/kernel:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/bias:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/kernel:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/bias:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_out_project/kernel:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_out_project/bias:0', 'stage_0_encoder_block_1_channel_attention_block_10_LayerNorm/gamma:0', 'stage_0_encoder_block_1_channel_attention_block_10_LayerNorm/beta:0', 'stage_0_encoder_block_1_channel_attention_block_10_conv1/kernel:0', 'stage_0_encoder_block_1_channel_attention_block_10_conv1/bias:0', 'stage_0_encoder_block_1_channel_attention_block_10_conv2/kernel:0', 'stage_0_encoder_block_1_channel_attention_block_10_conv2/bias:0', 'conv2d_7/kernel:0', 'conv2d_7/bias:0', 'conv2d_8/kernel:0', 'conv2d_8/bias:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/gamma:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/beta:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_in_project/kernel:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_in_project/bias:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/gamma:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/beta:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/beta:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/kernel:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/bias:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/kernel:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/bias:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_6/kernel:0', 'dense_6/bias:0', 'dense_7/kernel:0', 'dense_7/bias:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/kernel:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/bias:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/kernel:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/bias:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_out_project/kernel:0', 'stage_0_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_out_project/bias:0', 'stage_0_encoder_block_1_channel_attention_block_11_LayerNorm/gamma:0', 'stage_0_encoder_block_1_channel_attention_block_11_LayerNorm/beta:0', 'stage_0_encoder_block_1_channel_attention_block_11_conv1/kernel:0', 'stage_0_encoder_block_1_channel_attention_block_11_conv1/bias:0', 'stage_0_encoder_block_1_channel_attention_block_11_conv2/kernel:0', 'stage_0_encoder_block_1_channel_attention_block_11_conv2/bias:0', 'conv2d_9/kernel:0', 'conv2d_9/bias:0', 'conv2d_10/kernel:0', 'conv2d_10/bias:0', 'conv2d_11/kernel:0', 'conv2d_11/bias:0', 'conv2d_12/kernel:0', 'conv2d_12/bias:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/gamma:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/beta:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_in_project/kernel:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_in_project/bias:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/gamma:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/beta:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/beta:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/kernel:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/bias:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/kernel:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/bias:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_8/kernel:0', 'dense_8/bias:0', 'dense_9/kernel:0', 'dense_9/bias:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/kernel:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/bias:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/kernel:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/bias:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_out_project/kernel:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_out_project/bias:0', 'stage_0_encoder_block_2_channel_attention_block_10_LayerNorm/gamma:0', 'stage_0_encoder_block_2_channel_attention_block_10_LayerNorm/beta:0', 'stage_0_encoder_block_2_channel_attention_block_10_conv1/kernel:0', 'stage_0_encoder_block_2_channel_attention_block_10_conv1/bias:0', 'stage_0_encoder_block_2_channel_attention_block_10_conv2/kernel:0', 'stage_0_encoder_block_2_channel_attention_block_10_conv2/bias:0', 'conv2d_13/kernel:0', 'conv2d_13/bias:0', 'conv2d_14/kernel:0', 'conv2d_14/bias:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/gamma:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/beta:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_in_project/kernel:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_in_project/bias:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/gamma:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/beta:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/beta:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/kernel:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/bias:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/kernel:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/bias:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_10/kernel:0', 'dense_10/bias:0', 'dense_11/kernel:0', 'dense_11/bias:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/kernel:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/bias:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/kernel:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/bias:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_out_project/kernel:0', 'stage_0_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_out_project/bias:0', 'stage_0_encoder_block_2_channel_attention_block_11_LayerNorm/gamma:0', 'stage_0_encoder_block_2_channel_attention_block_11_LayerNorm/beta:0', 'stage_0_encoder_block_2_channel_attention_block_11_conv1/kernel:0', 'stage_0_encoder_block_2_channel_attention_block_11_conv1/bias:0', 'stage_0_encoder_block_2_channel_attention_block_11_conv2/kernel:0', 'stage_0_encoder_block_2_channel_attention_block_11_conv2/bias:0', 'conv2d_15/kernel:0', 'conv2d_15/bias:0', 'conv2d_16/kernel:0', 'conv2d_16/bias:0', 'conv2d_17/kernel:0', 'conv2d_17/bias:0', 'stage_0_global_block_0_input_proj/kernel:0', 'stage_0_global_block_0_input_proj/bias:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/gamma:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/beta:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_0_in_project/kernel:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_0_in_project/bias:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/gamma:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/beta:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/beta:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/kernel:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/bias:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/kernel:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/bias:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_12/kernel:0', 'dense_12/bias:0', 'dense_13/kernel:0', 'dense_13/bias:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/kernel:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/bias:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/kernel:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/bias:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_0_out_project/kernel:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_0_out_project/bias:0', 'stage_0_global_block_0_channel_attention_block_1_0_LayerNorm/gamma:0', 'stage_0_global_block_0_channel_attention_block_1_0_LayerNorm/beta:0', 'dense_14/kernel:0', 'dense_14/bias:0', 'dense_15/kernel:0', 'dense_15/bias:0', 'conv2d_18/kernel:0', 'conv2d_18/bias:0', 'conv2d_19/kernel:0', 'conv2d_19/bias:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/gamma:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/beta:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_1_in_project/kernel:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_1_in_project/bias:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/gamma:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/beta:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/beta:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/kernel:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/bias:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/kernel:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/bias:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_16/kernel:0', 'dense_16/bias:0', 'dense_17/kernel:0', 'dense_17/bias:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/kernel:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/bias:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/kernel:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/bias:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_1_out_project/kernel:0', 'stage_0_global_block_0_SplitHeadMultiAxisGmlpLayer_1_out_project/bias:0', 'stage_0_global_block_0_channel_attention_block_1_1_LayerNorm/gamma:0', 'stage_0_global_block_0_channel_attention_block_1_1_LayerNorm/beta:0', 'dense_18/kernel:0', 'dense_18/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0', 'conv2d_20/kernel:0', 'conv2d_20/bias:0', 'conv2d_21/kernel:0', 'conv2d_21/bias:0', 'stage_0_global_block_1_input_proj/kernel:0', 'stage_0_global_block_1_input_proj/bias:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/gamma:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/beta:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_0_in_project/kernel:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_0_in_project/bias:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/gamma:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/beta:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/beta:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/kernel:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/bias:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/kernel:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/bias:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_20/kernel:0', 'dense_20/bias:0', 'dense_21/kernel:0', 'dense_21/bias:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/kernel:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/bias:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/kernel:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/bias:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_0_out_project/kernel:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_0_out_project/bias:0', 'stage_0_global_block_1_channel_attention_block_1_0_LayerNorm/gamma:0', 'stage_0_global_block_1_channel_attention_block_1_0_LayerNorm/beta:0', 'dense_22/kernel:0', 'dense_22/bias:0', 'dense_23/kernel:0', 'dense_23/bias:0', 'conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/gamma:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/beta:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_1_in_project/kernel:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_1_in_project/bias:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/gamma:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/beta:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/beta:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/kernel:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/bias:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/kernel:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/bias:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_24/kernel:0', 'dense_24/bias:0', 'dense_25/kernel:0', 'dense_25/bias:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/kernel:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/bias:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/kernel:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/bias:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_1_out_project/kernel:0', 'stage_0_global_block_1_SplitHeadMultiAxisGmlpLayer_1_out_project/bias:0', 'stage_0_global_block_1_channel_attention_block_1_1_LayerNorm/gamma:0', 'stage_0_global_block_1_channel_attention_block_1_1_LayerNorm/beta:0', 'stage_0_upsample_ratio_2_0_encoder_point_conv/kernel:0', 'stage_0_upsample_ratio_2_0_encoder_point_conv/bias:0', 'stage_0_upsample_ratio_2_1_encoder_point_conv/kernel:0', 'stage_0_upsample_ratio_2_1_encoder_point_conv/bias:0', 'stage_0_upsample_ratio_2_2_encoder_point_conv/kernel:0', 'stage_0_upsample_ratio_2_2_encoder_point_conv/bias:0', 'dense_26/kernel:0', 'dense_26/bias:0', 'conv2d_26/kernel:0', 'conv2d_26/bias:0', 'stage_0_cross_gating_block_2_LayerNorm_x/gamma:0', 'stage_0_cross_gating_block_2_LayerNorm_x/beta:0', 'dense_27/kernel:0', 'dense_27/bias:0', 'stage_0_cross_gating_block_2_in_project_x/kernel:0', 'stage_0_cross_gating_block_2_in_project_x/bias:0', 'conv2d_24/kernel:0', 'conv2d_24/bias:0', 'stage_0_cross_gating_block_2_SplitHeadMultiAxisGating_x_LayerNorm_in/gamma:0', 'stage_0_cross_gating_block_2_SplitHeadMultiAxisGating_x_LayerNorm_in/beta:0', 'stage_0_cross_gating_block_2_SplitHeadMultiAxisGating_x_in_project/kernel:0', 'stage_0_cross_gating_block_2_SplitHeadMultiAxisGating_x_in_project/bias:0', 'conv2d_25/kernel:0', 'conv2d_25/bias:0', 'stage_0_upsample_ratio_1_0_encoder_point_conv/kernel:0', 'stage_0_upsample_ratio_1_0_encoder_point_conv/bias:0', 'stage_0_upsample_ratio_1_1_encoder_point_conv/kernel:0', 'stage_0_upsample_ratio_1_1_encoder_point_conv/bias:0', 'stage_0_upsample_ratio_1_2_encoder_point_conv/kernel:0', 'stage_0_upsample_ratio_1_2_encoder_point_conv/bias:0', 'conv2d_28/kernel:0', 'conv2d_28/bias:0', 'dense_28/kernel:0', 'dense_28/bias:0', 'dense_29/kernel:0', 'dense_29/bias:0', 'stage_0_cross_gating_block_1_LayerNorm_x/gamma:0', 'stage_0_cross_gating_block_1_LayerNorm_x/beta:0', 'conv2d_transpose/kernel:0', 'conv2d_transpose/bias:0', 'stage_0_cross_gating_block_1_in_project_x/kernel:0', 'stage_0_cross_gating_block_1_in_project_x/bias:0', 'conv2d_27/kernel:0', 'conv2d_27/bias:0', 'stage_0_cross_gating_block_2_LayerNorm_y/gamma:0', 'stage_0_cross_gating_block_2_LayerNorm_y/beta:0', 'stage_0_cross_gating_block_1_SplitHeadMultiAxisGating_x_LayerNorm_in/gamma:0', 'stage_0_cross_gating_block_1_SplitHeadMultiAxisGating_x_LayerNorm_in/beta:0', 'stage_0_cross_gating_block_2_in_project_y/kernel:0', 'stage_0_cross_gating_block_2_in_project_y/bias:0', 'stage_0_cross_gating_block_2_SplitHeadMultiAxisGating_x_out_project/kernel:0', 'stage_0_cross_gating_block_2_SplitHeadMultiAxisGating_x_out_project/bias:0', 'stage_0_cross_gating_block_1_SplitHeadMultiAxisGating_x_in_project/kernel:0', 'stage_0_cross_gating_block_1_SplitHeadMultiAxisGating_x_in_project/bias:0', 'stage_0_cross_gating_block_2_out_project_y/kernel:0', 'stage_0_cross_gating_block_2_out_project_y/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'conv2d_transpose_1/kernel:0', 'conv2d_transpose_1/bias:0', 'conv2d_29/kernel:0', 'conv2d_29/bias:0', 'stage_0_cross_gating_block_1_LayerNorm_y/gamma:0', 'stage_0_cross_gating_block_1_LayerNorm_y/beta:0', 'stage_0_cross_gating_block_1_in_project_y/kernel:0', 'stage_0_cross_gating_block_1_in_project_y/bias:0', 'stage_0_cross_gating_block_1_SplitHeadMultiAxisGating_x_out_project/kernel:0', 'stage_0_cross_gating_block_1_SplitHeadMultiAxisGating_x_out_project/bias:0', 'stage_0_cross_gating_block_1_out_project_y/kernel:0', 'stage_0_cross_gating_block_1_out_project_y/bias:0', 'stage_0_upsample_ratio_0_0_encoder_point_conv/kernel:0', 'stage_0_upsample_ratio_0_0_encoder_point_conv/bias:0', 'stage_0_upsample_ratio_0_1_encoder_point_conv/kernel:0', 'stage_0_upsample_ratio_0_1_encoder_point_conv/bias:0', 'stage_0_upsample_ratio_0_2_encoder_point_conv/kernel:0', 'stage_0_upsample_ratio_0_2_encoder_point_conv/bias:0', 'conv2d_30/kernel:0', 'conv2d_30/bias:0', 'conv2d_transpose_2/kernel:0', 'conv2d_transpose_2/bias:0', 'stage_0_cross_gating_block_0_LayerNorm_x/gamma:0', 'stage_0_cross_gating_block_0_LayerNorm_x/beta:0', 'conv2d_31/kernel:0', 'conv2d_31/bias:0', 'stage_0_cross_gating_block_0_in_project_x/kernel:0', 'stage_0_cross_gating_block_0_in_project_x/bias:0', 'stage_0_cross_gating_block_0_LayerNorm_y/gamma:0', 'stage_0_cross_gating_block_0_LayerNorm_y/beta:0', 'stage_0_cross_gating_block_0_in_project_y/kernel:0', 'stage_0_cross_gating_block_0_in_project_y/bias:0', 'stage_0_cross_gating_block_0_SplitHeadMultiAxisGating_x_LayerNorm_in/gamma:0', 'stage_0_cross_gating_block_0_SplitHeadMultiAxisGating_x_LayerNorm_in/beta:0', 'stage_0_cross_gating_block_2_SplitHeadMultiAxisGating_y_LayerNorm_in/gamma:0', 'stage_0_cross_gating_block_2_SplitHeadMultiAxisGating_y_LayerNorm_in/beta:0', 'stage_0_cross_gating_block_1_SplitHeadMultiAxisGating_y_LayerNorm_in/gamma:0', 'stage_0_cross_gating_block_1_SplitHeadMultiAxisGating_y_LayerNorm_in/beta:0', 'stage_0_cross_gating_block_0_SplitHeadMultiAxisGating_y_LayerNorm_in/gamma:0', 'stage_0_cross_gating_block_0_SplitHeadMultiAxisGating_y_LayerNorm_in/beta:0', 'stage_0_cross_gating_block_0_SplitHeadMultiAxisGating_x_in_project/kernel:0', 'stage_0_cross_gating_block_0_SplitHeadMultiAxisGating_x_in_project/bias:0', 'stage_0_cross_gating_block_2_SplitHeadMultiAxisGating_y_in_project/kernel:0', 'stage_0_cross_gating_block_2_SplitHeadMultiAxisGating_y_in_project/bias:0', 'stage_0_cross_gating_block_1_SplitHeadMultiAxisGating_y_in_project/kernel:0', 'stage_0_cross_gating_block_1_SplitHeadMultiAxisGating_y_in_project/bias:0', 'stage_0_cross_gating_block_0_SplitHeadMultiAxisGating_y_in_project/kernel:0', 'stage_0_cross_gating_block_0_SplitHeadMultiAxisGating_y_in_project/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'stage_0_cross_gating_block_0_SplitHeadMultiAxisGating_x_out_project/kernel:0', 'stage_0_cross_gating_block_0_SplitHeadMultiAxisGating_x_out_project/bias:0', 'stage_0_cross_gating_block_2_SplitHeadMultiAxisGating_y_out_project/kernel:0', 'stage_0_cross_gating_block_2_SplitHeadMultiAxisGating_y_out_project/bias:0', 'stage_0_cross_gating_block_1_SplitHeadMultiAxisGating_y_out_project/kernel:0', 'stage_0_cross_gating_block_1_SplitHeadMultiAxisGating_y_out_project/bias:0', 'stage_0_cross_gating_block_0_SplitHeadMultiAxisGating_y_out_project/kernel:0', 'stage_0_cross_gating_block_0_SplitHeadMultiAxisGating_y_out_project/bias:0', 'stage_0_cross_gating_block_0_out_project_y/kernel:0', 'stage_0_cross_gating_block_0_out_project_y/bias:0', 'stage_0_cross_gating_block_2_out_project_x/kernel:0', 'stage_0_cross_gating_block_2_out_project_x/bias:0', 'stage_0_cross_gating_block_1_out_project_x/kernel:0', 'stage_0_cross_gating_block_1_out_project_x/bias:0', 'stage_0_cross_gating_block_0_out_project_x/kernel:0', 'stage_0_cross_gating_block_0_out_project_x/bias:0', 'stage_0_upsample_ratio_2_0_decoder_point_conv/kernel:0', 'stage_0_upsample_ratio_2_0_decoder_point_conv/bias:0', 'stage_0_upsample_ratio_2_1_decoder_point_conv/kernel:0', 'stage_0_upsample_ratio_2_1_decoder_point_conv/bias:0', 'stage_0_upsample_ratio_2_2_decoder_point_conv/kernel:0', 'stage_0_upsample_ratio_2_2_decoder_point_conv/bias:0', 'conv2d_transpose_3/kernel:0', 'conv2d_transpose_3/bias:0', 'conv2d_32/kernel:0', 'conv2d_32/bias:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/gamma:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/beta:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_in_project/kernel:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_in_project/bias:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/gamma:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/beta:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/beta:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/kernel:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/bias:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/kernel:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/bias:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_40/kernel:0', 'dense_40/bias:0', 'dense_41/kernel:0', 'dense_41/bias:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/kernel:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/bias:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/kernel:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/bias:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_out_project/kernel:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_out_project/bias:0', 'stage_0_decoder_block_2_unet_encoder_channel_attention_block_10_LayerNorm/gamma:0', 'stage_0_decoder_block_2_unet_encoder_channel_attention_block_10_LayerNorm/beta:0', 'stage_0_decoder_block_2_unet_encoder_channel_attention_block_10_conv1/kernel:0', 'stage_0_decoder_block_2_unet_encoder_channel_attention_block_10_conv1/bias:0', 'stage_0_decoder_block_2_unet_encoder_channel_attention_block_10_conv2/kernel:0', 'stage_0_decoder_block_2_unet_encoder_channel_attention_block_10_conv2/bias:0', 'conv2d_33/kernel:0', 'conv2d_33/bias:0', 'conv2d_34/kernel:0', 'conv2d_34/bias:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/gamma:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/beta:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_in_project/kernel:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_in_project/bias:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/gamma:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/beta:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/beta:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/kernel:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/bias:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/kernel:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/bias:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_42/kernel:0', 'dense_42/bias:0', 'dense_43/kernel:0', 'dense_43/bias:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/kernel:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/bias:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/kernel:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/bias:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_out_project/kernel:0', 'stage_0_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_out_project/bias:0', 'stage_0_decoder_block_2_unet_encoder_channel_attention_block_11_LayerNorm/gamma:0', 'stage_0_decoder_block_2_unet_encoder_channel_attention_block_11_LayerNorm/beta:0', 'stage_0_decoder_block_2_unet_encoder_channel_attention_block_11_conv1/kernel:0', 'stage_0_decoder_block_2_unet_encoder_channel_attention_block_11_conv1/bias:0', 'stage_0_decoder_block_2_unet_encoder_channel_attention_block_11_conv2/kernel:0', 'stage_0_decoder_block_2_unet_encoder_channel_attention_block_11_conv2/bias:0', 'conv2d_35/kernel:0', 'conv2d_35/bias:0', 'conv2d_36/kernel:0', 'conv2d_36/bias:0', 'stage_0_upsample_ratio_1_0_decoder_point_conv/kernel:0', 'stage_0_upsample_ratio_1_0_decoder_point_conv/bias:0', 'stage_0_upsample_ratio_1_1_decoder_point_conv/kernel:0', 'stage_0_upsample_ratio_1_1_decoder_point_conv/bias:0', 'stage_0_upsample_ratio_1_2_decoder_point_conv/kernel:0', 'stage_0_upsample_ratio_1_2_decoder_point_conv/bias:0', 'conv2d_transpose_4/kernel:0', 'conv2d_transpose_4/bias:0', 'conv2d_37/kernel:0', 'conv2d_37/bias:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/gamma:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/beta:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_in_project/kernel:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_in_project/bias:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/gamma:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/beta:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/beta:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/kernel:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/bias:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/kernel:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/bias:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_44/kernel:0', 'dense_44/bias:0', 'dense_45/kernel:0', 'dense_45/bias:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/kernel:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/bias:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/kernel:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/bias:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_out_project/kernel:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_out_project/bias:0', 'stage_0_decoder_block_1_unet_encoder_channel_attention_block_10_LayerNorm/gamma:0', 'stage_0_decoder_block_1_unet_encoder_channel_attention_block_10_LayerNorm/beta:0', 'stage_0_decoder_block_1_unet_encoder_channel_attention_block_10_conv1/kernel:0', 'stage_0_decoder_block_1_unet_encoder_channel_attention_block_10_conv1/bias:0', 'stage_0_decoder_block_1_unet_encoder_channel_attention_block_10_conv2/kernel:0', 'stage_0_decoder_block_1_unet_encoder_channel_attention_block_10_conv2/bias:0', 'conv2d_38/kernel:0', 'conv2d_38/bias:0', 'conv2d_39/kernel:0', 'conv2d_39/bias:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/gamma:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/beta:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_in_project/kernel:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_in_project/bias:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/gamma:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/beta:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/beta:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/kernel:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/bias:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/kernel:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/bias:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_46/kernel:0', 'dense_46/bias:0', 'dense_47/kernel:0', 'dense_47/bias:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/kernel:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/bias:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/kernel:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/bias:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_out_project/kernel:0', 'stage_0_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_out_project/bias:0', 'stage_0_decoder_block_1_unet_encoder_channel_attention_block_11_LayerNorm/gamma:0', 'stage_0_decoder_block_1_unet_encoder_channel_attention_block_11_LayerNorm/beta:0', 'stage_0_decoder_block_1_unet_encoder_channel_attention_block_11_conv1/kernel:0', 'stage_0_decoder_block_1_unet_encoder_channel_attention_block_11_conv1/bias:0', 'stage_0_decoder_block_1_unet_encoder_channel_attention_block_11_conv2/kernel:0', 'stage_0_decoder_block_1_unet_encoder_channel_attention_block_11_conv2/bias:0', 'conv2d_40/kernel:0', 'conv2d_40/bias:0', 'conv2d_41/kernel:0', 'conv2d_41/bias:0', 'stage_0_upsample_ratio_0_0_decoder_point_conv/kernel:0', 'stage_0_upsample_ratio_0_0_decoder_point_conv/bias:0', 'stage_0_upsample_ratio_0_1_decoder_point_conv/kernel:0', 'stage_0_upsample_ratio_0_1_decoder_point_conv/bias:0', 'stage_0_upsample_ratio_0_2_decoder_point_conv/kernel:0', 'stage_0_upsample_ratio_0_2_decoder_point_conv/bias:0', 'conv2d_transpose_5/kernel:0', 'conv2d_transpose_5/bias:0', 'conv2d_42/kernel:0', 'conv2d_42/bias:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/gamma:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/beta:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_in_project/kernel:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_in_project/bias:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/gamma:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/beta:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/beta:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/kernel:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/bias:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/kernel:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/bias:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_48/kernel:0', 'dense_48/bias:0', 'dense_49/kernel:0', 'dense_49/bias:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/kernel:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/bias:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/kernel:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/bias:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_out_project/kernel:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_out_project/bias:0', 'stage_0_decoder_block_0_unet_encoder_channel_attention_block_10_LayerNorm/gamma:0', 'stage_0_decoder_block_0_unet_encoder_channel_attention_block_10_LayerNorm/beta:0', 'stage_0_decoder_block_0_unet_encoder_channel_attention_block_10_conv1/kernel:0', 'stage_0_decoder_block_0_unet_encoder_channel_attention_block_10_conv1/bias:0', 'stage_0_decoder_block_0_unet_encoder_channel_attention_block_10_conv2/kernel:0', 'stage_0_decoder_block_0_unet_encoder_channel_attention_block_10_conv2/bias:0', 'conv2d_43/kernel:0', 'conv2d_43/bias:0', 'conv2d_44/kernel:0', 'conv2d_44/bias:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/gamma:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/beta:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_in_project/kernel:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_in_project/bias:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/gamma:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/beta:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/beta:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/kernel:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/bias:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/kernel:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/bias:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_50/kernel:0', 'dense_50/bias:0', 'dense_51/kernel:0', 'dense_51/bias:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/kernel:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/bias:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/kernel:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/bias:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_out_project/kernel:0', 'stage_0_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_out_project/bias:0', 'stage_0_decoder_block_0_unet_encoder_channel_attention_block_11_LayerNorm/gamma:0', 'stage_0_decoder_block_0_unet_encoder_channel_attention_block_11_LayerNorm/beta:0', 'stage_0_decoder_block_0_unet_encoder_channel_attention_block_11_conv1/kernel:0', 'stage_0_decoder_block_0_unet_encoder_channel_attention_block_11_conv1/bias:0', 'stage_0_decoder_block_0_unet_encoder_channel_attention_block_11_conv2/kernel:0', 'stage_0_decoder_block_0_unet_encoder_channel_attention_block_11_conv2/bias:0', 'conv2d_45/kernel:0', 'conv2d_45/bias:0', 'conv2d_46/kernel:0', 'conv2d_46/bias:0', 'conv2d_48/kernel:0', 'conv2d_48/bias:0', 'conv2d_49/kernel:0', 'conv2d_49/bias:0', 'conv2d_47/kernel:0', 'conv2d_47/bias:0', 'stage_1_input_conv_0/kernel:0', 'stage_1_input_conv_0/bias:0', 'conv2d_50/kernel:0', 'conv2d_50/bias:0', 'stage_1_input_fuse_sam_0_LayerNorm_x/gamma:0', 'stage_1_input_fuse_sam_0_LayerNorm_x/beta:0', 'conv2d_51/kernel:0', 'conv2d_51/bias:0', 'stage_1_input_fuse_sam_0_in_project_x/kernel:0', 'stage_1_input_fuse_sam_0_in_project_x/bias:0', 'stage_1_input_fuse_sam_0_LayerNorm_y/gamma:0', 'stage_1_input_fuse_sam_0_LayerNorm_y/beta:0', 'stage_1_input_fuse_sam_0_in_project_y/kernel:0', 'stage_1_input_fuse_sam_0_in_project_y/bias:0', 'stage_1_input_fuse_sam_0_SplitHeadMultiAxisGating_x_LayerNorm_in/gamma:0', 'stage_1_input_fuse_sam_0_SplitHeadMultiAxisGating_x_LayerNorm_in/beta:0', 'stage_1_input_fuse_sam_0_SplitHeadMultiAxisGating_y_LayerNorm_in/gamma:0', 'stage_1_input_fuse_sam_0_SplitHeadMultiAxisGating_y_LayerNorm_in/beta:0', 'stage_1_input_fuse_sam_0_SplitHeadMultiAxisGating_x_in_project/kernel:0', 'stage_1_input_fuse_sam_0_SplitHeadMultiAxisGating_x_in_project/bias:0', 'stage_1_input_fuse_sam_0_SplitHeadMultiAxisGating_y_in_project/kernel:0', 'stage_1_input_fuse_sam_0_SplitHeadMultiAxisGating_y_in_project/bias:0', 'dense_52/kernel:0', 'dense_52/bias:0', 'dense_53/kernel:0', 'dense_53/bias:0', 'dense_54/kernel:0', 'dense_54/bias:0', 'dense_55/kernel:0', 'dense_55/bias:0', 'stage_1_input_fuse_sam_0_SplitHeadMultiAxisGating_x_out_project/kernel:0', 'stage_1_input_fuse_sam_0_SplitHeadMultiAxisGating_x_out_project/bias:0', 'stage_1_input_fuse_sam_0_SplitHeadMultiAxisGating_y_out_project/kernel:0', 'stage_1_input_fuse_sam_0_SplitHeadMultiAxisGating_y_out_project/bias:0', 'stage_1_input_fuse_sam_0_out_project_y/kernel:0', 'stage_1_input_fuse_sam_0_out_project_y/bias:0', 'stage_1_input_fuse_sam_0_out_project_x/kernel:0', 'stage_1_input_fuse_sam_0_out_project_x/bias:0', 'conv2d_52/kernel:0', 'conv2d_52/bias:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/gamma:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/beta:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_in_project/kernel:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_in_project/bias:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/gamma:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/beta:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/beta:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/kernel:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/bias:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/kernel:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/bias:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_56/kernel:0', 'dense_56/bias:0', 'dense_57/kernel:0', 'dense_57/bias:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/kernel:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/bias:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/kernel:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/bias:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_out_project/kernel:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_out_project/bias:0', 'stage_1_encoder_block_0_channel_attention_block_10_LayerNorm/gamma:0', 'stage_1_encoder_block_0_channel_attention_block_10_LayerNorm/beta:0', 'stage_1_encoder_block_0_channel_attention_block_10_conv1/kernel:0', 'stage_1_encoder_block_0_channel_attention_block_10_conv1/bias:0', 'stage_1_encoder_block_0_channel_attention_block_10_conv2/kernel:0', 'stage_1_encoder_block_0_channel_attention_block_10_conv2/bias:0', 'conv2d_53/kernel:0', 'conv2d_53/bias:0', 'conv2d_54/kernel:0', 'conv2d_54/bias:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/gamma:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/beta:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_in_project/kernel:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_in_project/bias:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/gamma:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/beta:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/beta:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/kernel:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/bias:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/kernel:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/bias:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_58/kernel:0', 'dense_58/bias:0', 'dense_59/kernel:0', 'dense_59/bias:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/kernel:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/bias:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/kernel:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/bias:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_out_project/kernel:0', 'stage_1_encoder_block_0_SplitHeadMultiAxisGmlpLayer_1_out_project/bias:0', 'stage_1_encoder_block_0_channel_attention_block_11_LayerNorm/gamma:0', 'stage_1_encoder_block_0_channel_attention_block_11_LayerNorm/beta:0', 'stage_1_encoder_block_0_channel_attention_block_11_conv1/kernel:0', 'stage_1_encoder_block_0_channel_attention_block_11_conv1/bias:0', 'stage_1_encoder_block_0_channel_attention_block_11_conv2/kernel:0', 'stage_1_encoder_block_0_channel_attention_block_11_conv2/bias:0', 'conv2d_55/kernel:0', 'conv2d_55/bias:0', 'conv2d_56/kernel:0', 'conv2d_56/bias:0', 'conv2d_57/kernel:0', 'conv2d_57/bias:0', 'stage_1_encoder_block_0_cross_gating_block_LayerNorm_x/gamma:0', 'stage_1_encoder_block_0_cross_gating_block_LayerNorm_x/beta:0', 'conv2d_58/kernel:0', 'conv2d_58/bias:0', 'stage_1_encoder_block_0_cross_gating_block_in_project_x/kernel:0', 'stage_1_encoder_block_0_cross_gating_block_in_project_x/bias:0', 'stage_1_encoder_block_0_cross_gating_block_LayerNorm_y/gamma:0', 'stage_1_encoder_block_0_cross_gating_block_LayerNorm_y/beta:0', 'stage_1_encoder_block_0_cross_gating_block_in_project_y/kernel:0', 'stage_1_encoder_block_0_cross_gating_block_in_project_y/bias:0', 'stage_1_encoder_block_0_cross_gating_block_SplitHeadMultiAxisGating_x_LayerNorm_in/gamma:0', 'stage_1_encoder_block_0_cross_gating_block_SplitHeadMultiAxisGating_x_LayerNorm_in/beta:0', 'stage_1_encoder_block_0_cross_gating_block_SplitHeadMultiAxisGating_y_LayerNorm_in/gamma:0', 'stage_1_encoder_block_0_cross_gating_block_SplitHeadMultiAxisGating_y_LayerNorm_in/beta:0', 'stage_1_encoder_block_0_cross_gating_block_SplitHeadMultiAxisGating_x_in_project/kernel:0', 'stage_1_encoder_block_0_cross_gating_block_SplitHeadMultiAxisGating_x_in_project/bias:0', 'stage_1_encoder_block_0_cross_gating_block_SplitHeadMultiAxisGating_y_in_project/kernel:0', 'stage_1_encoder_block_0_cross_gating_block_SplitHeadMultiAxisGating_y_in_project/bias:0', 'dense_60/kernel:0', 'dense_60/bias:0', 'dense_61/kernel:0', 'dense_61/bias:0', 'dense_62/kernel:0', 'dense_62/bias:0', 'dense_63/kernel:0', 'dense_63/bias:0', 'stage_1_encoder_block_0_cross_gating_block_SplitHeadMultiAxisGating_x_out_project/kernel:0', 'stage_1_encoder_block_0_cross_gating_block_SplitHeadMultiAxisGating_x_out_project/bias:0', 'stage_1_encoder_block_0_cross_gating_block_SplitHeadMultiAxisGating_y_out_project/kernel:0', 'stage_1_encoder_block_0_cross_gating_block_SplitHeadMultiAxisGating_y_out_project/bias:0', 'stage_1_encoder_block_0_cross_gating_block_out_project_y/kernel:0', 'stage_1_encoder_block_0_cross_gating_block_out_project_y/bias:0', 'stage_1_encoder_block_0_cross_gating_block_out_project_x/kernel:0', 'stage_1_encoder_block_0_cross_gating_block_out_project_x/bias:0', 'conv2d_59/kernel:0', 'conv2d_59/bias:0', 'conv2d_60/kernel:0', 'conv2d_60/bias:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/gamma:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/beta:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_in_project/kernel:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_in_project/bias:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/gamma:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/beta:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/beta:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/kernel:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/bias:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/kernel:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/bias:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_64/kernel:0', 'dense_64/bias:0', 'dense_65/kernel:0', 'dense_65/bias:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/kernel:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/bias:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/kernel:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/bias:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_out_project/kernel:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_0_out_project/bias:0', 'stage_1_encoder_block_1_channel_attention_block_10_LayerNorm/gamma:0', 'stage_1_encoder_block_1_channel_attention_block_10_LayerNorm/beta:0', 'stage_1_encoder_block_1_channel_attention_block_10_conv1/kernel:0', 'stage_1_encoder_block_1_channel_attention_block_10_conv1/bias:0', 'stage_1_encoder_block_1_channel_attention_block_10_conv2/kernel:0', 'stage_1_encoder_block_1_channel_attention_block_10_conv2/bias:0', 'conv2d_61/kernel:0', 'conv2d_61/bias:0', 'conv2d_62/kernel:0', 'conv2d_62/bias:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/gamma:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/beta:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_in_project/kernel:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_in_project/bias:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/gamma:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/beta:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/beta:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/kernel:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/bias:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/kernel:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/bias:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_66/kernel:0', 'dense_66/bias:0', 'dense_67/kernel:0', 'dense_67/bias:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/kernel:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/bias:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/kernel:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/bias:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_out_project/kernel:0', 'stage_1_encoder_block_1_SplitHeadMultiAxisGmlpLayer_1_out_project/bias:0', 'stage_1_encoder_block_1_channel_attention_block_11_LayerNorm/gamma:0', 'stage_1_encoder_block_1_channel_attention_block_11_LayerNorm/beta:0', 'stage_1_encoder_block_1_channel_attention_block_11_conv1/kernel:0', 'stage_1_encoder_block_1_channel_attention_block_11_conv1/bias:0', 'stage_1_encoder_block_1_channel_attention_block_11_conv2/kernel:0', 'stage_1_encoder_block_1_channel_attention_block_11_conv2/bias:0', 'conv2d_63/kernel:0', 'conv2d_63/bias:0', 'conv2d_64/kernel:0', 'conv2d_64/bias:0', 'conv2d_65/kernel:0', 'conv2d_65/bias:0', 'stage_1_encoder_block_1_cross_gating_block_LayerNorm_x/gamma:0', 'stage_1_encoder_block_1_cross_gating_block_LayerNorm_x/beta:0', 'conv2d_66/kernel:0', 'conv2d_66/bias:0', 'stage_1_encoder_block_1_cross_gating_block_in_project_x/kernel:0', 'stage_1_encoder_block_1_cross_gating_block_in_project_x/bias:0', 'stage_1_encoder_block_1_cross_gating_block_LayerNorm_y/gamma:0', 'stage_1_encoder_block_1_cross_gating_block_LayerNorm_y/beta:0', 'stage_1_encoder_block_1_cross_gating_block_in_project_y/kernel:0', 'stage_1_encoder_block_1_cross_gating_block_in_project_y/bias:0', 'stage_1_encoder_block_1_cross_gating_block_SplitHeadMultiAxisGating_x_LayerNorm_in/gamma:0', 'stage_1_encoder_block_1_cross_gating_block_SplitHeadMultiAxisGating_x_LayerNorm_in/beta:0', 'stage_1_encoder_block_1_cross_gating_block_SplitHeadMultiAxisGating_y_LayerNorm_in/gamma:0', 'stage_1_encoder_block_1_cross_gating_block_SplitHeadMultiAxisGating_y_LayerNorm_in/beta:0', 'stage_1_encoder_block_1_cross_gating_block_SplitHeadMultiAxisGating_x_in_project/kernel:0', 'stage_1_encoder_block_1_cross_gating_block_SplitHeadMultiAxisGating_x_in_project/bias:0', 'stage_1_encoder_block_1_cross_gating_block_SplitHeadMultiAxisGating_y_in_project/kernel:0', 'stage_1_encoder_block_1_cross_gating_block_SplitHeadMultiAxisGating_y_in_project/bias:0', 'dense_68/kernel:0', 'dense_68/bias:0', 'dense_69/kernel:0', 'dense_69/bias:0', 'dense_70/kernel:0', 'dense_70/bias:0', 'dense_71/kernel:0', 'dense_71/bias:0', 'stage_1_encoder_block_1_cross_gating_block_SplitHeadMultiAxisGating_x_out_project/kernel:0', 'stage_1_encoder_block_1_cross_gating_block_SplitHeadMultiAxisGating_x_out_project/bias:0', 'stage_1_encoder_block_1_cross_gating_block_SplitHeadMultiAxisGating_y_out_project/kernel:0', 'stage_1_encoder_block_1_cross_gating_block_SplitHeadMultiAxisGating_y_out_project/bias:0', 'stage_1_encoder_block_1_cross_gating_block_out_project_y/kernel:0', 'stage_1_encoder_block_1_cross_gating_block_out_project_y/bias:0', 'stage_1_encoder_block_1_cross_gating_block_out_project_x/kernel:0', 'stage_1_encoder_block_1_cross_gating_block_out_project_x/bias:0', 'conv2d_67/kernel:0', 'conv2d_67/bias:0', 'conv2d_68/kernel:0', 'conv2d_68/bias:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/gamma:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/beta:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_in_project/kernel:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_in_project/bias:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/gamma:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/beta:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/beta:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/kernel:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/bias:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/kernel:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/bias:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_72/kernel:0', 'dense_72/bias:0', 'dense_73/kernel:0', 'dense_73/bias:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/kernel:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/bias:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/kernel:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/bias:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_out_project/kernel:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_0_out_project/bias:0', 'stage_1_encoder_block_2_channel_attention_block_10_LayerNorm/gamma:0', 'stage_1_encoder_block_2_channel_attention_block_10_LayerNorm/beta:0', 'stage_1_encoder_block_2_channel_attention_block_10_conv1/kernel:0', 'stage_1_encoder_block_2_channel_attention_block_10_conv1/bias:0', 'stage_1_encoder_block_2_channel_attention_block_10_conv2/kernel:0', 'stage_1_encoder_block_2_channel_attention_block_10_conv2/bias:0', 'conv2d_69/kernel:0', 'conv2d_69/bias:0', 'conv2d_70/kernel:0', 'conv2d_70/bias:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/gamma:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/beta:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_in_project/kernel:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_in_project/bias:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/gamma:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/beta:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/beta:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/kernel:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/bias:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/kernel:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/bias:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_74/kernel:0', 'dense_74/bias:0', 'dense_75/kernel:0', 'dense_75/bias:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/kernel:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/bias:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/kernel:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/bias:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_out_project/kernel:0', 'stage_1_encoder_block_2_SplitHeadMultiAxisGmlpLayer_1_out_project/bias:0', 'stage_1_encoder_block_2_channel_attention_block_11_LayerNorm/gamma:0', 'stage_1_encoder_block_2_channel_attention_block_11_LayerNorm/beta:0', 'stage_1_encoder_block_2_channel_attention_block_11_conv1/kernel:0', 'stage_1_encoder_block_2_channel_attention_block_11_conv1/bias:0', 'stage_1_encoder_block_2_channel_attention_block_11_conv2/kernel:0', 'stage_1_encoder_block_2_channel_attention_block_11_conv2/bias:0', 'conv2d_71/kernel:0', 'conv2d_71/bias:0', 'conv2d_72/kernel:0', 'conv2d_72/bias:0', 'conv2d_73/kernel:0', 'conv2d_73/bias:0', 'stage_1_encoder_block_2_cross_gating_block_LayerNorm_x/gamma:0', 'stage_1_encoder_block_2_cross_gating_block_LayerNorm_x/beta:0', 'conv2d_74/kernel:0', 'conv2d_74/bias:0', 'stage_1_encoder_block_2_cross_gating_block_in_project_x/kernel:0', 'stage_1_encoder_block_2_cross_gating_block_in_project_x/bias:0', 'stage_1_encoder_block_2_cross_gating_block_LayerNorm_y/gamma:0', 'stage_1_encoder_block_2_cross_gating_block_LayerNorm_y/beta:0', 'stage_1_encoder_block_2_cross_gating_block_in_project_y/kernel:0', 'stage_1_encoder_block_2_cross_gating_block_in_project_y/bias:0', 'stage_1_encoder_block_2_cross_gating_block_SplitHeadMultiAxisGating_x_LayerNorm_in/gamma:0', 'stage_1_encoder_block_2_cross_gating_block_SplitHeadMultiAxisGating_x_LayerNorm_in/beta:0', 'stage_1_encoder_block_2_cross_gating_block_SplitHeadMultiAxisGating_y_LayerNorm_in/gamma:0', 'stage_1_encoder_block_2_cross_gating_block_SplitHeadMultiAxisGating_y_LayerNorm_in/beta:0', 'stage_1_encoder_block_2_cross_gating_block_SplitHeadMultiAxisGating_x_in_project/kernel:0', 'stage_1_encoder_block_2_cross_gating_block_SplitHeadMultiAxisGating_x_in_project/bias:0', 'stage_1_encoder_block_2_cross_gating_block_SplitHeadMultiAxisGating_y_in_project/kernel:0', 'stage_1_encoder_block_2_cross_gating_block_SplitHeadMultiAxisGating_y_in_project/bias:0', 'dense_76/kernel:0', 'dense_76/bias:0', 'dense_77/kernel:0', 'dense_77/bias:0', 'dense_78/kernel:0', 'dense_78/bias:0', 'dense_79/kernel:0', 'dense_79/bias:0', 'stage_1_encoder_block_2_cross_gating_block_SplitHeadMultiAxisGating_x_out_project/kernel:0', 'stage_1_encoder_block_2_cross_gating_block_SplitHeadMultiAxisGating_x_out_project/bias:0', 'stage_1_encoder_block_2_cross_gating_block_SplitHeadMultiAxisGating_y_out_project/kernel:0', 'stage_1_encoder_block_2_cross_gating_block_SplitHeadMultiAxisGating_y_out_project/bias:0', 'stage_1_encoder_block_2_cross_gating_block_out_project_y/kernel:0', 'stage_1_encoder_block_2_cross_gating_block_out_project_y/bias:0', 'stage_1_encoder_block_2_cross_gating_block_out_project_x/kernel:0', 'stage_1_encoder_block_2_cross_gating_block_out_project_x/bias:0', 'conv2d_75/kernel:0', 'conv2d_75/bias:0', 'stage_1_global_block_0_input_proj/kernel:0', 'stage_1_global_block_0_input_proj/bias:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/gamma:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/beta:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_0_in_project/kernel:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_0_in_project/bias:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/gamma:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/beta:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/beta:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/kernel:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/bias:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/kernel:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/bias:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_80/kernel:0', 'dense_80/bias:0', 'dense_81/kernel:0', 'dense_81/bias:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/kernel:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/bias:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/kernel:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/bias:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_0_out_project/kernel:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_0_out_project/bias:0', 'stage_1_global_block_0_channel_attention_block_1_0_LayerNorm/gamma:0', 'stage_1_global_block_0_channel_attention_block_1_0_LayerNorm/beta:0', 'dense_82/kernel:0', 'dense_82/bias:0', 'dense_83/kernel:0', 'dense_83/bias:0', 'conv2d_76/kernel:0', 'conv2d_76/bias:0', 'conv2d_77/kernel:0', 'conv2d_77/bias:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/gamma:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/beta:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_1_in_project/kernel:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_1_in_project/bias:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/gamma:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/beta:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/beta:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/kernel:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/bias:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/kernel:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/bias:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_84/kernel:0', 'dense_84/bias:0', 'dense_85/kernel:0', 'dense_85/bias:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/kernel:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/bias:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/kernel:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/bias:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_1_out_project/kernel:0', 'stage_1_global_block_0_SplitHeadMultiAxisGmlpLayer_1_out_project/bias:0', 'stage_1_global_block_0_channel_attention_block_1_1_LayerNorm/gamma:0', 'stage_1_global_block_0_channel_attention_block_1_1_LayerNorm/beta:0', 'dense_86/kernel:0', 'dense_86/bias:0', 'dense_87/kernel:0', 'dense_87/bias:0', 'conv2d_78/kernel:0', 'conv2d_78/bias:0', 'conv2d_79/kernel:0', 'conv2d_79/bias:0', 'stage_1_global_block_1_input_proj/kernel:0', 'stage_1_global_block_1_input_proj/bias:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/gamma:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/beta:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_0_in_project/kernel:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_0_in_project/bias:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/gamma:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/beta:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/beta:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/kernel:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/bias:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/kernel:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/bias:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_88/kernel:0', 'dense_88/bias:0', 'dense_89/kernel:0', 'dense_89/bias:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/kernel:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/bias:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/kernel:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/bias:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_0_out_project/kernel:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_0_out_project/bias:0', 'stage_1_global_block_1_channel_attention_block_1_0_LayerNorm/gamma:0', 'stage_1_global_block_1_channel_attention_block_1_0_LayerNorm/beta:0', 'dense_90/kernel:0', 'dense_90/bias:0', 'dense_91/kernel:0', 'dense_91/bias:0', 'conv2d_80/kernel:0', 'conv2d_80/bias:0', 'conv2d_81/kernel:0', 'conv2d_81/bias:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/gamma:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/beta:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_1_in_project/kernel:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_1_in_project/bias:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/gamma:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/beta:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/beta:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/kernel:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/bias:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/kernel:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/bias:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_92/kernel:0', 'dense_92/bias:0', 'dense_93/kernel:0', 'dense_93/bias:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/kernel:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/bias:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/kernel:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/bias:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_1_out_project/kernel:0', 'stage_1_global_block_1_SplitHeadMultiAxisGmlpLayer_1_out_project/bias:0', 'stage_1_global_block_1_channel_attention_block_1_1_LayerNorm/gamma:0', 'stage_1_global_block_1_channel_attention_block_1_1_LayerNorm/beta:0', 'stage_1_upsample_ratio_2_0_encoder_point_conv/kernel:0', 'stage_1_upsample_ratio_2_0_encoder_point_conv/bias:0', 'stage_1_upsample_ratio_2_1_encoder_point_conv/kernel:0', 'stage_1_upsample_ratio_2_1_encoder_point_conv/bias:0', 'stage_1_upsample_ratio_2_2_encoder_point_conv/kernel:0', 'stage_1_upsample_ratio_2_2_encoder_point_conv/bias:0', 'dense_94/kernel:0', 'dense_94/bias:0', 'conv2d_84/kernel:0', 'conv2d_84/bias:0', 'stage_1_cross_gating_block_2_LayerNorm_x/gamma:0', 'stage_1_cross_gating_block_2_LayerNorm_x/beta:0', 'dense_95/kernel:0', 'dense_95/bias:0', 'stage_1_cross_gating_block_2_in_project_x/kernel:0', 'stage_1_cross_gating_block_2_in_project_x/bias:0', 'conv2d_82/kernel:0', 'conv2d_82/bias:0', 'stage_1_cross_gating_block_2_SplitHeadMultiAxisGating_x_LayerNorm_in/gamma:0', 'stage_1_cross_gating_block_2_SplitHeadMultiAxisGating_x_LayerNorm_in/beta:0', 'stage_1_cross_gating_block_2_SplitHeadMultiAxisGating_x_in_project/kernel:0', 'stage_1_cross_gating_block_2_SplitHeadMultiAxisGating_x_in_project/bias:0', 'conv2d_83/kernel:0', 'conv2d_83/bias:0', 'stage_1_upsample_ratio_1_0_encoder_point_conv/kernel:0', 'stage_1_upsample_ratio_1_0_encoder_point_conv/bias:0', 'stage_1_upsample_ratio_1_1_encoder_point_conv/kernel:0', 'stage_1_upsample_ratio_1_1_encoder_point_conv/bias:0', 'stage_1_upsample_ratio_1_2_encoder_point_conv/kernel:0', 'stage_1_upsample_ratio_1_2_encoder_point_conv/bias:0', 'conv2d_86/kernel:0', 'conv2d_86/bias:0', 'dense_96/kernel:0', 'dense_96/bias:0', 'dense_97/kernel:0', 'dense_97/bias:0', 'stage_1_cross_gating_block_1_LayerNorm_x/gamma:0', 'stage_1_cross_gating_block_1_LayerNorm_x/beta:0', 'conv2d_transpose_6/kernel:0', 'conv2d_transpose_6/bias:0', 'stage_1_cross_gating_block_1_in_project_x/kernel:0', 'stage_1_cross_gating_block_1_in_project_x/bias:0', 'conv2d_85/kernel:0', 'conv2d_85/bias:0', 'stage_1_cross_gating_block_2_LayerNorm_y/gamma:0', 'stage_1_cross_gating_block_2_LayerNorm_y/beta:0', 'stage_1_cross_gating_block_1_SplitHeadMultiAxisGating_x_LayerNorm_in/gamma:0', 'stage_1_cross_gating_block_1_SplitHeadMultiAxisGating_x_LayerNorm_in/beta:0', 'stage_1_cross_gating_block_2_in_project_y/kernel:0', 'stage_1_cross_gating_block_2_in_project_y/bias:0', 'stage_1_cross_gating_block_2_SplitHeadMultiAxisGating_x_out_project/kernel:0', 'stage_1_cross_gating_block_2_SplitHeadMultiAxisGating_x_out_project/bias:0', 'stage_1_cross_gating_block_1_SplitHeadMultiAxisGating_x_in_project/kernel:0', 'stage_1_cross_gating_block_1_SplitHeadMultiAxisGating_x_in_project/bias:0', 'stage_1_cross_gating_block_2_out_project_y/kernel:0', 'stage_1_cross_gating_block_2_out_project_y/bias:0', 'dense_100/kernel:0', 'dense_100/bias:0', 'dense_101/kernel:0', 'dense_101/bias:0', 'conv2d_transpose_7/kernel:0', 'conv2d_transpose_7/bias:0', 'conv2d_87/kernel:0', 'conv2d_87/bias:0', 'stage_1_cross_gating_block_1_LayerNorm_y/gamma:0', 'stage_1_cross_gating_block_1_LayerNorm_y/beta:0', 'stage_1_cross_gating_block_1_in_project_y/kernel:0', 'stage_1_cross_gating_block_1_in_project_y/bias:0', 'stage_1_cross_gating_block_1_SplitHeadMultiAxisGating_x_out_project/kernel:0', 'stage_1_cross_gating_block_1_SplitHeadMultiAxisGating_x_out_project/bias:0', 'stage_1_cross_gating_block_1_out_project_y/kernel:0', 'stage_1_cross_gating_block_1_out_project_y/bias:0', 'stage_1_upsample_ratio_0_0_encoder_point_conv/kernel:0', 'stage_1_upsample_ratio_0_0_encoder_point_conv/bias:0', 'stage_1_upsample_ratio_0_1_encoder_point_conv/kernel:0', 'stage_1_upsample_ratio_0_1_encoder_point_conv/bias:0', 'stage_1_upsample_ratio_0_2_encoder_point_conv/kernel:0', 'stage_1_upsample_ratio_0_2_encoder_point_conv/bias:0', 'conv2d_88/kernel:0', 'conv2d_88/bias:0', 'conv2d_transpose_8/kernel:0', 'conv2d_transpose_8/bias:0', 'stage_1_cross_gating_block_0_LayerNorm_x/gamma:0', 'stage_1_cross_gating_block_0_LayerNorm_x/beta:0', 'conv2d_89/kernel:0', 'conv2d_89/bias:0', 'stage_1_cross_gating_block_0_in_project_x/kernel:0', 'stage_1_cross_gating_block_0_in_project_x/bias:0', 'stage_1_cross_gating_block_0_LayerNorm_y/gamma:0', 'stage_1_cross_gating_block_0_LayerNorm_y/beta:0', 'stage_1_cross_gating_block_0_in_project_y/kernel:0', 'stage_1_cross_gating_block_0_in_project_y/bias:0', 'stage_1_cross_gating_block_0_SplitHeadMultiAxisGating_x_LayerNorm_in/gamma:0', 'stage_1_cross_gating_block_0_SplitHeadMultiAxisGating_x_LayerNorm_in/beta:0', 'stage_1_cross_gating_block_2_SplitHeadMultiAxisGating_y_LayerNorm_in/gamma:0', 'stage_1_cross_gating_block_2_SplitHeadMultiAxisGating_y_LayerNorm_in/beta:0', 'stage_1_cross_gating_block_1_SplitHeadMultiAxisGating_y_LayerNorm_in/gamma:0', 'stage_1_cross_gating_block_1_SplitHeadMultiAxisGating_y_LayerNorm_in/beta:0', 'stage_1_cross_gating_block_0_SplitHeadMultiAxisGating_y_LayerNorm_in/gamma:0', 'stage_1_cross_gating_block_0_SplitHeadMultiAxisGating_y_LayerNorm_in/beta:0', 'stage_1_cross_gating_block_0_SplitHeadMultiAxisGating_x_in_project/kernel:0', 'stage_1_cross_gating_block_0_SplitHeadMultiAxisGating_x_in_project/bias:0', 'stage_1_cross_gating_block_2_SplitHeadMultiAxisGating_y_in_project/kernel:0', 'stage_1_cross_gating_block_2_SplitHeadMultiAxisGating_y_in_project/bias:0', 'stage_1_cross_gating_block_1_SplitHeadMultiAxisGating_y_in_project/kernel:0', 'stage_1_cross_gating_block_1_SplitHeadMultiAxisGating_y_in_project/bias:0', 'stage_1_cross_gating_block_0_SplitHeadMultiAxisGating_y_in_project/kernel:0', 'stage_1_cross_gating_block_0_SplitHeadMultiAxisGating_y_in_project/bias:0', 'dense_104/kernel:0', 'dense_104/bias:0', 'dense_105/kernel:0', 'dense_105/bias:0', 'dense_98/kernel:0', 'dense_98/bias:0', 'dense_99/kernel:0', 'dense_99/bias:0', 'dense_102/kernel:0', 'dense_102/bias:0', 'dense_103/kernel:0', 'dense_103/bias:0', 'dense_106/kernel:0', 'dense_106/bias:0', 'dense_107/kernel:0', 'dense_107/bias:0', 'stage_1_cross_gating_block_0_SplitHeadMultiAxisGating_x_out_project/kernel:0', 'stage_1_cross_gating_block_0_SplitHeadMultiAxisGating_x_out_project/bias:0', 'stage_1_cross_gating_block_2_SplitHeadMultiAxisGating_y_out_project/kernel:0', 'stage_1_cross_gating_block_2_SplitHeadMultiAxisGating_y_out_project/bias:0', 'stage_1_cross_gating_block_1_SplitHeadMultiAxisGating_y_out_project/kernel:0', 'stage_1_cross_gating_block_1_SplitHeadMultiAxisGating_y_out_project/bias:0', 'stage_1_cross_gating_block_0_SplitHeadMultiAxisGating_y_out_project/kernel:0', 'stage_1_cross_gating_block_0_SplitHeadMultiAxisGating_y_out_project/bias:0', 'stage_1_cross_gating_block_0_out_project_y/kernel:0', 'stage_1_cross_gating_block_0_out_project_y/bias:0', 'stage_1_cross_gating_block_2_out_project_x/kernel:0', 'stage_1_cross_gating_block_2_out_project_x/bias:0', 'stage_1_cross_gating_block_1_out_project_x/kernel:0', 'stage_1_cross_gating_block_1_out_project_x/bias:0', 'stage_1_cross_gating_block_0_out_project_x/kernel:0', 'stage_1_cross_gating_block_0_out_project_x/bias:0', 'stage_1_upsample_ratio_2_0_decoder_point_conv/kernel:0', 'stage_1_upsample_ratio_2_0_decoder_point_conv/bias:0', 'stage_1_upsample_ratio_2_1_decoder_point_conv/kernel:0', 'stage_1_upsample_ratio_2_1_decoder_point_conv/bias:0', 'stage_1_upsample_ratio_2_2_decoder_point_conv/kernel:0', 'stage_1_upsample_ratio_2_2_decoder_point_conv/bias:0', 'conv2d_transpose_9/kernel:0', 'conv2d_transpose_9/bias:0', 'conv2d_90/kernel:0', 'conv2d_90/bias:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/gamma:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/beta:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_in_project/kernel:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_in_project/bias:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/gamma:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/beta:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/beta:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/kernel:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/bias:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/kernel:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/bias:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_108/kernel:0', 'dense_108/bias:0', 'dense_109/kernel:0', 'dense_109/bias:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/kernel:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/bias:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/kernel:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/bias:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_out_project/kernel:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_out_project/bias:0', 'stage_1_decoder_block_2_unet_encoder_channel_attention_block_10_LayerNorm/gamma:0', 'stage_1_decoder_block_2_unet_encoder_channel_attention_block_10_LayerNorm/beta:0', 'stage_1_decoder_block_2_unet_encoder_channel_attention_block_10_conv1/kernel:0', 'stage_1_decoder_block_2_unet_encoder_channel_attention_block_10_conv1/bias:0', 'stage_1_decoder_block_2_unet_encoder_channel_attention_block_10_conv2/kernel:0', 'stage_1_decoder_block_2_unet_encoder_channel_attention_block_10_conv2/bias:0', 'conv2d_91/kernel:0', 'conv2d_91/bias:0', 'conv2d_92/kernel:0', 'conv2d_92/bias:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/gamma:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/beta:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_in_project/kernel:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_in_project/bias:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/gamma:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/beta:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/beta:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/kernel:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/bias:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/kernel:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/bias:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_110/kernel:0', 'dense_110/bias:0', 'dense_111/kernel:0', 'dense_111/bias:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/kernel:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/bias:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/kernel:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/bias:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_out_project/kernel:0', 'stage_1_decoder_block_2_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_out_project/bias:0', 'stage_1_decoder_block_2_unet_encoder_channel_attention_block_11_LayerNorm/gamma:0', 'stage_1_decoder_block_2_unet_encoder_channel_attention_block_11_LayerNorm/beta:0', 'stage_1_decoder_block_2_unet_encoder_channel_attention_block_11_conv1/kernel:0', 'stage_1_decoder_block_2_unet_encoder_channel_attention_block_11_conv1/bias:0', 'stage_1_decoder_block_2_unet_encoder_channel_attention_block_11_conv2/kernel:0', 'stage_1_decoder_block_2_unet_encoder_channel_attention_block_11_conv2/bias:0', 'conv2d_93/kernel:0', 'conv2d_93/bias:0', 'conv2d_94/kernel:0', 'conv2d_94/bias:0', 'stage_1_upsample_ratio_1_0_decoder_point_conv/kernel:0', 'stage_1_upsample_ratio_1_0_decoder_point_conv/bias:0', 'stage_1_upsample_ratio_1_1_decoder_point_conv/kernel:0', 'stage_1_upsample_ratio_1_1_decoder_point_conv/bias:0', 'stage_1_upsample_ratio_1_2_decoder_point_conv/kernel:0', 'stage_1_upsample_ratio_1_2_decoder_point_conv/bias:0', 'conv2d_transpose_10/kernel:0', 'conv2d_transpose_10/bias:0', 'conv2d_95/kernel:0', 'conv2d_95/bias:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/gamma:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/beta:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_in_project/kernel:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_in_project/bias:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/gamma:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/beta:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/beta:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/kernel:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/bias:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/kernel:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/bias:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_112/kernel:0', 'dense_112/bias:0', 'dense_113/kernel:0', 'dense_113/bias:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/kernel:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/bias:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/kernel:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/bias:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_out_project/kernel:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_out_project/bias:0', 'stage_1_decoder_block_1_unet_encoder_channel_attention_block_10_LayerNorm/gamma:0', 'stage_1_decoder_block_1_unet_encoder_channel_attention_block_10_LayerNorm/beta:0', 'stage_1_decoder_block_1_unet_encoder_channel_attention_block_10_conv1/kernel:0', 'stage_1_decoder_block_1_unet_encoder_channel_attention_block_10_conv1/bias:0', 'stage_1_decoder_block_1_unet_encoder_channel_attention_block_10_conv2/kernel:0', 'stage_1_decoder_block_1_unet_encoder_channel_attention_block_10_conv2/bias:0', 'conv2d_96/kernel:0', 'conv2d_96/bias:0', 'conv2d_97/kernel:0', 'conv2d_97/bias:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/gamma:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/beta:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_in_project/kernel:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_in_project/bias:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/gamma:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/beta:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/beta:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/kernel:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/bias:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/kernel:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/bias:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_114/kernel:0', 'dense_114/bias:0', 'dense_115/kernel:0', 'dense_115/bias:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/kernel:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/bias:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/kernel:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/bias:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_out_project/kernel:0', 'stage_1_decoder_block_1_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_out_project/bias:0', 'stage_1_decoder_block_1_unet_encoder_channel_attention_block_11_LayerNorm/gamma:0', 'stage_1_decoder_block_1_unet_encoder_channel_attention_block_11_LayerNorm/beta:0', 'stage_1_decoder_block_1_unet_encoder_channel_attention_block_11_conv1/kernel:0', 'stage_1_decoder_block_1_unet_encoder_channel_attention_block_11_conv1/bias:0', 'stage_1_decoder_block_1_unet_encoder_channel_attention_block_11_conv2/kernel:0', 'stage_1_decoder_block_1_unet_encoder_channel_attention_block_11_conv2/bias:0', 'conv2d_98/kernel:0', 'conv2d_98/bias:0', 'conv2d_99/kernel:0', 'conv2d_99/bias:0', 'stage_1_upsample_ratio_0_0_decoder_point_conv/kernel:0', 'stage_1_upsample_ratio_0_0_decoder_point_conv/bias:0', 'stage_1_upsample_ratio_0_1_decoder_point_conv/kernel:0', 'stage_1_upsample_ratio_0_1_decoder_point_conv/bias:0', 'stage_1_upsample_ratio_0_2_decoder_point_conv/kernel:0', 'stage_1_upsample_ratio_0_2_decoder_point_conv/bias:0', 'conv2d_transpose_11/kernel:0', 'conv2d_transpose_11/bias:0', 'conv2d_100/kernel:0', 'conv2d_100/bias:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/gamma:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/beta:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_in_project/kernel:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_in_project/bias:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/gamma:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_LayerNorm/beta:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_LayerNorm/beta:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/kernel:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_in_project/bias:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/kernel:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_in_project/bias:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_116/kernel:0', 'dense_116/bias:0', 'dense_117/kernel:0', 'dense_117/bias:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/kernel:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_GridGmlpLayer_out_project/bias:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/kernel:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_BlockGmlpLayer_out_project/bias:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_out_project/kernel:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_0_out_project/bias:0', 'stage_1_decoder_block_0_unet_encoder_channel_attention_block_10_LayerNorm/gamma:0', 'stage_1_decoder_block_0_unet_encoder_channel_attention_block_10_LayerNorm/beta:0', 'stage_1_decoder_block_0_unet_encoder_channel_attention_block_10_conv1/kernel:0', 'stage_1_decoder_block_0_unet_encoder_channel_attention_block_10_conv1/bias:0', 'stage_1_decoder_block_0_unet_encoder_channel_attention_block_10_conv2/kernel:0', 'stage_1_decoder_block_0_unet_encoder_channel_attention_block_10_conv2/bias:0', 'conv2d_101/kernel:0', 'conv2d_101/bias:0', 'conv2d_102/kernel:0', 'conv2d_102/bias:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/gamma:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_LayerNorm_in/beta:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_in_project/kernel:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_in_project/bias:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/gamma:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_LayerNorm/beta:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/gamma:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_LayerNorm/beta:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/kernel:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_in_project/bias:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/kernel:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_in_project/bias:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_GridGatingUnit_intermediate_layernorm/beta:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/gamma:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_BlockGatingUnit_intermediate_layernorm/beta:0', 'dense_118/kernel:0', 'dense_118/bias:0', 'dense_119/kernel:0', 'dense_119/bias:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/kernel:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_GridGmlpLayer_out_project/bias:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/kernel:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_BlockGmlpLayer_out_project/bias:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_out_project/kernel:0', 'stage_1_decoder_block_0_unet_encoder_SplitHeadMultiAxisGmlpLayer_1_out_project/bias:0', 'stage_1_decoder_block_0_unet_encoder_channel_attention_block_11_LayerNorm/gamma:0', 'stage_1_decoder_block_0_unet_encoder_channel_attention_block_11_LayerNorm/beta:0', 'stage_1_decoder_block_0_unet_encoder_channel_attention_block_11_conv1/kernel:0', 'stage_1_decoder_block_0_unet_encoder_channel_attention_block_11_conv1/bias:0', 'stage_1_decoder_block_0_unet_encoder_channel_attention_block_11_conv2/kernel:0', 'stage_1_decoder_block_0_unet_encoder_channel_attention_block_11_conv2/bias:0', 'conv2d_103/kernel:0', 'conv2d_103/bias:0', 'conv2d_104/kernel:0', 'conv2d_104/bias:0', 'stage_1_output_conv_0/kernel:0', 'stage_1_output_conv_0/bias:0'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = maxim_s1(tf.ones((1, 256, 256, 3)), training=False)\n",
    "\n",
    "model_variables_dict = get_model_vars(maxim_s1)\n",
    "model_variables_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage_0_upsample_ratio_2_0_encoder_point_conv/kernel:0 (1, 1, 32, 128)\n"
     ]
    }
   ],
   "source": [
    "for k in model_variables_dict.keys():\n",
    "    if \"upsample\" in k:\n",
    "        print(k, model_variables_dict[k].shape)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "scratchpad",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
